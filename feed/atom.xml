<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom"><title>Nairobi LUG</title><link href="https://nairobilug.or.ke/" rel="alternate"></link><link href="https://nairobilug.or.ke/feed/atom.xml" rel="self"></link><id>https://nairobilug.or.ke/</id><updated>2015-09-02T11:00:00+03:00</updated><entry><title>Mounting Partitions Using systemd</title><link href="https://nairobilug.or.ke/2015/09/systemd-mount-partition.html" rel="alternate"></link><updated>2015-09-02T11:00:00+03:00</updated><author><name>James Oguya</name></author><id>tag:nairobilug.or.ke,2015-09-02:2015/09/systemd-mount-partition.html</id><summary type="html">&lt;p&gt;&lt;a href="http://www.freedesktop.org/wiki/Software/systemd"&gt;systemd&lt;/a&gt; is gradually becoming the de facto init system &amp;amp; service manager replacing the old sysV init scripts &amp;amp; upstart. Recently, I discovered you can mount partitions using &lt;a href="http://www.freedesktop.org/software/systemd/man/systemd.mount.html"&gt;systemd.mount&lt;/a&gt; by writing your own &lt;code&gt;.mount&lt;/code&gt; &lt;a href="http://www.freedesktop.org/software/systemd/man/systemd.unit.html"&gt;systemd unit file&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;img alt="super suprised" src="/images/2015-09-02-systemd-mount-partition/suprised-cat.jpg" /&gt;&lt;/p&gt;
&lt;p&gt;After &lt;em&gt;RTFM'ing&lt;/em&gt;, I realized, under the hood, systemd just runs &lt;a href="http://linux.die.net/man/8/mount"&gt;mount command&lt;/a&gt; to mount the specified partition with the specified mount options listed in the mount unit file. Basically, you need to specify the following options in your unit file:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;What=&lt;/code&gt; a partition name, path or UUID to mount&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Where=&lt;/code&gt; an absolute path of a directory i.e. path to a mount point. If the mount point is non-existent, it will be created&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Type=&lt;/code&gt; file system type. In most cases &lt;a href="http://linux.die.net/man/8/mount"&gt;mount command&lt;/a&gt; auto-detects the file system&lt;/li&gt;
&lt;li&gt;&lt;code&gt;Options=&lt;/code&gt; Mount options to use when mounting&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In the end, you can convert your typical fstab entry such as this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;UUID=86fef3b2-bdc9-47fa-bbb1-4e528a89d222 /mnt/backups    ext4    defaults      0 0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;to:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;[Mount]&lt;/span&gt;
&lt;span class="na"&gt;What&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/dev/disk/by-uuid/86fef3b2-bdc9-47fa-bbb1-4e528a89d222&lt;/span&gt;
&lt;span class="na"&gt;Where&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/mnt/backups&lt;/span&gt;
&lt;span class="na"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;ext4&lt;/span&gt;
&lt;span class="na"&gt;Options&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;defaults&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="I Got This!" src="/images/2015-09-02-systemd-mount-partition/i-got-this.gif" /&gt;&lt;/p&gt;
&lt;p&gt;So I wrote a simple systemd mount unit file — &lt;code&gt;/etc/systemd/system/mnt-backups.mount&lt;/code&gt; — which didn't work at first because I fell victim to one of the &lt;code&gt;systemd.mount&lt;/code&gt; pitfalls:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Mount units must be named after the mount point directories they control. Example: the mount point /home/lennart must be configured in a unit file home-lennart.mount.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Huh? Yes that's right! The unit filename should match the mount point path.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;mnt-backups.mount&lt;/code&gt; mount unit file:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;[Unit]&lt;/span&gt;
&lt;span class="na"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Mount System Backups Directory&lt;/span&gt;

&lt;span class="k"&gt;[Mount]&lt;/span&gt;
&lt;span class="na"&gt;What&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/dev/disk/by-uuid/86fef3b2-bdc9-47fa-bbb1-4e528a89d222&lt;/span&gt;
&lt;span class="na"&gt;Where&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/mnt/backups&lt;/span&gt;
&lt;span class="na"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;ext4&lt;/span&gt;
&lt;span class="na"&gt;Options&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;defaults&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Reload systemd daemon &amp;amp; start the unit.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;systemctl daemon-reload
systemctl start mnt-backups.mount
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And just like any other unit, you can view its status using &lt;code&gt;systemctl status mnt-backups.mount&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nt"&gt;root&lt;/span&gt;&lt;span class="k"&gt;@vast&lt;/span&gt; &lt;span class="o"&gt;~&lt;/span&gt; &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;systemctl&lt;/span&gt; &lt;span class="nt"&gt;status&lt;/span&gt; &lt;span class="nt"&gt;mnt-backups&lt;/span&gt;&lt;span class="nc"&gt;.mount&lt;/span&gt;
&lt;span class="err"&gt;●&lt;/span&gt; &lt;span class="nt"&gt;mnt-backups&lt;/span&gt;&lt;span class="nc"&gt;.mount&lt;/span&gt; &lt;span class="nt"&gt;-&lt;/span&gt; &lt;span class="nt"&gt;Mount&lt;/span&gt; &lt;span class="nt"&gt;System&lt;/span&gt; &lt;span class="nt"&gt;Backups&lt;/span&gt; &lt;span class="nt"&gt;Directory&lt;/span&gt;
   &lt;span class="nt"&gt;Loaded&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;loaded&lt;/span&gt; &lt;span class="o"&gt;(/&lt;/span&gt;&lt;span class="nt"&gt;etc&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;systemd&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;system&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;mnt-backups&lt;/span&gt;&lt;span class="nc"&gt;.mount&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt; &lt;span class="nt"&gt;enabled&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="nt"&gt;vendor&lt;/span&gt; &lt;span class="nt"&gt;preset&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;disabled&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;
   &lt;span class="nt"&gt;Active&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;active&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;mounted&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt; &lt;span class="nt"&gt;since&lt;/span&gt; &lt;span class="nt"&gt;Mon&lt;/span&gt; &lt;span class="nt"&gt;2015-08-31&lt;/span&gt; &lt;span class="nt"&gt;08&lt;/span&gt;&lt;span class="nd"&gt;:09:15&lt;/span&gt; &lt;span class="nt"&gt;EAT&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt; &lt;span class="nt"&gt;2&lt;/span&gt; &lt;span class="nt"&gt;days&lt;/span&gt; &lt;span class="nt"&gt;ago&lt;/span&gt;
    &lt;span class="nt"&gt;Where&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;mnt&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;backups&lt;/span&gt;
     &lt;span class="nt"&gt;What&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;sdc&lt;/span&gt;
  &lt;span class="nt"&gt;Process&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;744&lt;/span&gt; &lt;span class="nt"&gt;ExecMount&lt;/span&gt;&lt;span class="o"&gt;=/&lt;/span&gt;&lt;span class="nt"&gt;bin&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;mount&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;dev&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;disk&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;by-uuid&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;86fef3b2-bdc9-47fa-bbb1-4e528a89d222&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;mnt&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;backups&lt;/span&gt; &lt;span class="nt"&gt;-n&lt;/span&gt; &lt;span class="nt"&gt;-t&lt;/span&gt; &lt;span class="nt"&gt;ext4&lt;/span&gt; &lt;span class="nt"&gt;-o&lt;/span&gt; &lt;span class="nt"&gt;defaults&lt;/span&gt; &lt;span class="o"&gt;(&lt;/span&gt;&lt;span class="nt"&gt;code&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;exited&lt;/span&gt;&lt;span class="o"&gt;,&lt;/span&gt; &lt;span class="nt"&gt;status&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="nt"&gt;0&lt;/span&gt;&lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;SUCCESS&lt;/span&gt;&lt;span class="o"&gt;)&lt;/span&gt;

&lt;span class="nt"&gt;Aug&lt;/span&gt; &lt;span class="nt"&gt;31&lt;/span&gt; &lt;span class="nt"&gt;08&lt;/span&gt;&lt;span class="nd"&gt;:09:15&lt;/span&gt; &lt;span class="nt"&gt;vast&lt;/span&gt; &lt;span class="nt"&gt;systemd&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;Mounting&lt;/span&gt; &lt;span class="nt"&gt;Mount&lt;/span&gt; &lt;span class="nt"&gt;System&lt;/span&gt; &lt;span class="nt"&gt;Backups&lt;/span&gt; &lt;span class="nt"&gt;Directory&lt;/span&gt;&lt;span class="o"&gt;...&lt;/span&gt;
&lt;span class="nt"&gt;Aug&lt;/span&gt; &lt;span class="nt"&gt;31&lt;/span&gt; &lt;span class="nt"&gt;08&lt;/span&gt;&lt;span class="nd"&gt;:09:15&lt;/span&gt; &lt;span class="nt"&gt;vast&lt;/span&gt; &lt;span class="nt"&gt;systemd&lt;/span&gt;&lt;span class="cp"&gt;[&lt;/span&gt;&lt;span class="mi"&gt;1&lt;/span&gt;&lt;span class="cp"&gt;]&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="nt"&gt;Mounted&lt;/span&gt; &lt;span class="nt"&gt;Mount&lt;/span&gt; &lt;span class="nt"&gt;System&lt;/span&gt; &lt;span class="nt"&gt;Backups&lt;/span&gt; &lt;span class="nt"&gt;Directory&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Gotchas!!&lt;/h2&gt;
&lt;p&gt;After a reboot, I noticed the unit wasn't started &amp;amp; as result the mount point dir. was empty. The unit file was missing an &lt;code&gt;[Install]&lt;/code&gt; section which contains installation information such as unit dependencies(&lt;code&gt;WantedBy=, RequiredBy=&lt;/code&gt;), aliases(&lt;code&gt;Alias=&lt;/code&gt;), additional units(&lt;code&gt;Also=&lt;/code&gt;), e.t.c for the specified unit. In this case, I set the unit to start in multi-user runlevel a.k.a &lt;code&gt;multi-user.target&lt;/code&gt;. Oh, did you know you can change runlevel using &lt;code&gt;systemctl isolate $RUN_LEVEL.target&lt;/code&gt;? &lt;a href="https://wiki.archlinux.org/index.php/Systemd#Targets_table"&gt;Read more&lt;/a&gt; about systemd runlevels/targets.&lt;/p&gt;
&lt;p&gt;Here's the complete &lt;code&gt;/etc/systemd/system/mnt-backups.mount&lt;/code&gt; unit file with an &lt;code&gt;[Install]&lt;/code&gt; section:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;[Unit]&lt;/span&gt;
&lt;span class="na"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Mount System Backups Directory&lt;/span&gt;

&lt;span class="k"&gt;[Mount]&lt;/span&gt;
&lt;span class="na"&gt;What&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/dev/disk/by-uuid/86fef3b2-bdc9-47fa-bbb1-4e528a89d222&lt;/span&gt;
&lt;span class="na"&gt;Where&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/mnt/backups&lt;/span&gt;
&lt;span class="na"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;ext4&lt;/span&gt;
&lt;span class="na"&gt;Options&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;defaults&lt;/span&gt;

&lt;span class="k"&gt;[Install]&lt;/span&gt;
&lt;span class="na"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;multi-user.target&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As always, enable the unit to start automatically during boot.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;systemctl &lt;span class="nb"&gt;enable &lt;/span&gt;mnt-backups.mount
&lt;/pre&gt;&lt;/div&gt;</summary><category term="linux"></category><category term="systemd"></category></entry><entry><title>Stop Skype and PulseAudio from "uncorking" media players</title><link href="https://nairobilug.or.ke/2015/08/stop-pulseaudio-uncorking.html" rel="alternate"></link><updated>2015-08-02T15:21:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2015-08-02:2015/08/stop-pulseaudio-uncorking.html</id><summary type="html">&lt;p&gt;PulseAudio has a neat feature that allows applications to "uncork" media players like Rhythmbox, Banshee, etc when certain events happen. For example: when a call comes in Skype pauses your music so you can answer without fiddling around to pause manually. Unfortunately Skype also deems the "contact coming online" and "contact going offline" events as worthy of uncorking, so your music gets interrupted for several seconds when these events fire (aka all the time).&lt;/p&gt;
&lt;h2&gt;Unload the "cork" module&lt;/h2&gt;
&lt;p&gt;A short term solution is to unload the corking module from your user's PulseAudio session:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;pactl unload-module module-role-cork
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That will take effect immediately for the remainder of the current user's session. A more permanent solution would be to comment out the loading of the "cork" module in PulseAudio's configuration file.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;/etc/pulse/default.pa&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;### Cork music/video streams when a phone stream is active
#load-module module-role-cork
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Other annoyances&lt;/h2&gt;
&lt;p&gt;Now if only there were a way to address some other Skype annoyances like requiring the installation of a bunch of 32-bit libraries or how chat windows hijack the desktop environment's alt-tab ordering when there is a new message. Oh, it would also be nice if there wasn't massive, gaping &lt;a href="http://www.theguardian.com/world/2013/jul/11/microsoft-nsa-collaboration-user-data"&gt;backdoor giving the NSA access to your chats&lt;/a&gt;. &lt;em&gt;*sigh*&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This was &lt;a href="https://mjanja.ch/2015/08/stop-skype-and-pulseaudio-from-uncorking-media-players/"&gt;originally posted&lt;/a&gt; on my personal blog; re-posted here for posterity.&lt;/p&gt;</summary><category term="linux"></category><category term="pulseaudio"></category><category term="skype"></category><category term="nsa"></category></entry><entry><title>Meetup Summary (July, 2015)</title><link href="https://nairobilug.or.ke/2015/07/meetup-july-2015.html" rel="alternate"></link><updated>2015-07-05T23:18:00+03:00</updated><author><name>Muriithi Frederick Muriuki</name></author><id>tag:nairobilug.or.ke,2015-07-05:2015/07/meetup-july-2015.html</id><summary type="html">&lt;p&gt;So, this month, only 4 people showed up in person, but the meeting turned out still interesting. Below is a summary of the things we talked about in no particular order:&lt;/p&gt;
&lt;h3&gt;Linux (duh...)&lt;/h3&gt;
&lt;p&gt;As usual, we spoke about Linux, giving various experiences, some of which were particularly funny. As such, I will note one such experience, which was interesting, while he was still a noob:&lt;/p&gt;
&lt;p&gt;There is a common trend on forums and irc for the more experienced folk to respond to noobs with RTFM, which each of us has at one point or the other experienced. The trouble with &lt;em&gt;nixes is that &lt;code&gt;rtfm&lt;/code&gt; could for all intents and purposes, be a valid &lt;/em&gt;nix command - so, in this case, our hapless noob went ahead and typed rtfm on his terminal emulator.
As is to be expected, we laughed our heads out... still, could there be a faster way to assist our noobs?&lt;/p&gt;
&lt;h3&gt;Education in Kenya&lt;/h3&gt;
&lt;p&gt;This topic was especially volatile, seeing as the four people who showed up were all patrons of the system. As it were, we all railed on the (perceived?) failings of our education system, especially it's insistence on papers, without actual skill acquisition.&lt;/p&gt;
&lt;p&gt;Someone pointed out how in his Engineering studies (in University), practicals using the lathe involved standing in a semi-circle watching the lab technician operate the device. As is expected, that was a blatant exaggeration to make a point, but it was not far from the truth in this case, seeing as most Universities in the country focus on earning money, without much focus on upgrading the equipment required for teaching the technical courses like Engineering.&lt;/p&gt;
&lt;p&gt;Someone also pointed out that one of the Universities is still teaching HTML 2.0 officially in it's Computer Science Curriculum - go figure.&lt;/p&gt;
&lt;h3&gt;Hackathons, Conferences, etc&lt;/h3&gt;
&lt;p&gt;There was a slight segway into talks about various conferences, and how in Kenya, there seems to be a dearth of information on things like venues and times. Someone suggested that the organisers might be afraid that the NairobiLUG might criticise them &lt;a href="https://nairobilug.or.ke/2015/05/brck-violating-gpl.html"&gt;as it did BRCK&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;We laughed that off as unlikely and quickly moved on.&lt;/p&gt;
&lt;h3&gt;Computer Security&lt;/h3&gt;
&lt;p&gt;There was an anecdote to the effect that the security organs in the country might be frowning upon discussions on computer security.&lt;/p&gt;
&lt;p&gt;It was also stated that a lot of banks in the country might be using ciphers that are known to be broken and vulnerable for years now, but raising that with the concerned parties is likely to land you in jail, rather than having the issue fixed.&lt;/p&gt;
&lt;p&gt;On that chilling note, we moved along swiftly.&lt;/p&gt;
&lt;h3&gt;The Kenic/CA Farce&lt;/h3&gt;
&lt;p&gt;There was a discussion on the news in &lt;a href="http://www.nation.co.ke/news/CA-WiFi-Internet-Rules-Cybercrime/-/1056/2771118/-/mbci1a/-/index.html"&gt;this article&lt;/a&gt; regarding Kenic and the Communications Authority requiring registration of gadgets to access Wi-Fi.&lt;/p&gt;
&lt;p&gt;There was a general consensus that the people who came up with these kind of rules do not understand how the technology works, and willfully refuse to consult with and listen to those who do.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;While this is the least attended meetup in a really long time, it turned out to be really fascinating and fun.&lt;/p&gt;
&lt;p&gt;I encourage people to show up to the next meeting on 01 August, 2015.&lt;/p&gt;</summary><category term="KFC"></category><category term="meetup"></category></entry><entry><title>Meetup Summary (June, 2015)</title><link href="https://nairobilug.or.ke/2015/06/meetup-june-2015.html" rel="alternate"></link><updated>2015-06-14T17:25:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2015-06-14:2015/06/meetup-june-2015.html</id><summary type="html">&lt;p&gt;While I never tire of general chit chat about Linux and the broader free, libre, open-source software ecosystem, it is always nice when a meetup goes beyond that. This month we were lucky to have a few new faces drop by and shake up the monotony a bit. ;)&lt;/p&gt;
&lt;h3&gt;Tunapanda&lt;/h3&gt;
&lt;p&gt;A few teachers and trainers from the &lt;a href="http://tunapanda.org/"&gt;Tunapanda Institute&lt;/a&gt; came by and talked about their work in the community. As a bonus, they brought their &lt;a href="http://www.cubietruck.com/"&gt;CubieTruck&lt;/a&gt; single-board mini PC which is running a modified Edubuntu, and is packed with a few hundred gigs(!) of open course content. Once booted up the device creates an open Wi-Fi access point that allows anyone to access its content via a built-in web server. &lt;/p&gt;
&lt;p&gt;They've even got some of the nuts and bolts for provisioning and managing this process on &lt;a href="https://github.com/tunapanda"&gt;their GitHub account&lt;/a&gt;!&lt;/p&gt;
&lt;h3&gt;BRCK&lt;/h3&gt;
&lt;p&gt;After &lt;a href="https://nairobilug.or.ke/2015/05/meetup-may-2015.html"&gt;last month's&lt;/a&gt; discussion of &lt;a href="https://nairobilug.or.ke/2015/05/brck-violating-gpl.html"&gt;BRCK's GPL violation&lt;/a&gt; BRCK reached out to us and resolved things amicably. In addition to posting &lt;a href="https://www.brck.com/open-source-compliance/"&gt;source code for their BRCKv1&lt;/a&gt; a few of their people came to the meetup to talk about OpenWRT, single-board computers, and fried chicken.&lt;/p&gt;
&lt;p&gt;Furthermore, we discussed the role that the community can play in getting the word about companies that are friendly to open-source hardware and software. Simple things like how to flash vanilla software for devices, where to get source code, how to set up a build environment, unbricking, teardowns, etc. In that light, BRCK has donated one BRCKv1 unit to the LUG so we can pass it around, hack on it, and write about it.&lt;/p&gt;
&lt;p&gt;Here's an unboxing video we shot to kick things off...&lt;/p&gt;
&lt;iframe width="640" height="360" src="https://www.youtube-nocookie.com/embed/SV9qVZQcKck" frameborder="0" allowfullscreen&gt;&lt;/iframe&gt;

&lt;p&gt;We'll post more when we get time!&lt;/p&gt;
&lt;h3&gt;Open all teh things&lt;/h3&gt;
&lt;p&gt;We briefly discussed the closed-minded culture of information and data sharing in science, but how things are changing because donors who fund research — like the &lt;a href="http://www.gatesfoundation.org/"&gt;Bill and Melinda Gates Foundation&lt;/a&gt;, the &lt;a href="http://www.usaid.gov/"&gt;United States Agency for International Development&lt;/a&gt; (USAID), the &lt;a href="https://www.gov.uk/government/organisations/department-for-international-development"&gt;Department for International Development&lt;/a&gt; (DFID), etc — are calling for the results of all new research to be free and open. Even so, in April the Elsevier group of scientific journals announced their &lt;a href="https://www.elsevier.com/connect/elsevier-updates-its-policies-perspectives-and-services-on-article-sharing"&gt;new sharing policy&lt;/a&gt; which requires publications to be licensed Creative Commons, but with the restrictive no commercial (NC) and no derivatives (ND) clauses.&lt;/p&gt;
&lt;p&gt;We were reminded of the late Aaron Swartz's &lt;a href="https://archive.org/stream/GuerillaOpenAccessManifesto/Goamjuly2008_djvu.txt"&gt;Guerilla Open Access Manifesto&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;Until next time&lt;/h3&gt;
&lt;p&gt;As per our schedule of meeting on the first Saturday of the month, the next meeting should be on July 4th. Until next time, wathii!&lt;/p&gt;</summary><category term="KFC"></category><category term="meetup"></category></entry><entry><title>Replacing cron jobs with systemd timers</title><link href="https://nairobilug.or.ke/2015/06/cron-systemd-timers.html" rel="alternate"></link><updated>2015-06-08T15:21:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2015-06-08:2015/06/cron-systemd-timers.html</id><summary type="html">&lt;p&gt;systemd has a timer function that can be used to run tasks periodically — yes, like &lt;code&gt;cron&lt;/code&gt;. There's nothing really wrong with cron, but have you ever tried to debug a cron job on a server? The script runs fine from the command line, but nothing seems to happen when it runs from cron. You quickly type &lt;code&gt;date&lt;/code&gt; to see how many seconds until the next minute, adjust the cron job, and wait. Nothing. Repeat. &lt;em&gt;*facedesk*&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;This is the systemd value proposition in this context: &lt;em&gt;timers can be run on demand&lt;/em&gt; from the command line, and &lt;em&gt;their output is logged to the systemd journal&lt;/em&gt; where you can see it like any other systemd units.&lt;/p&gt;
&lt;h2&gt;System backups using a timer&lt;/h2&gt;
&lt;p&gt;As an example, I have a simple shell script — &lt;code&gt;system-backup.sh&lt;/code&gt; — that uses &lt;code&gt;rsync&lt;/code&gt; to back up my system to an external USB hard drive once per day. Converting this job to use systemd timers requires the creation of both a &lt;em&gt;timer&lt;/em&gt; and a &lt;em&gt;service&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;/etc/systemd/system/system-backup.timer&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;[Unit]&lt;/span&gt;
&lt;span class="na"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Perform system backup&lt;/span&gt;

&lt;span class="k"&gt;[Timer]&lt;/span&gt;
&lt;span class="na"&gt;OnCalendar&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;daily&lt;/span&gt;

&lt;span class="k"&gt;[Install]&lt;/span&gt;
&lt;span class="na"&gt;WantedBy&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;timers.target&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;em&gt;/etc/systemd/system/system-backup.service&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="k"&gt;[Unit]&lt;/span&gt;
&lt;span class="na"&gt;Description&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;Perform system backup&lt;/span&gt;

&lt;span class="k"&gt;[Service]&lt;/span&gt;
&lt;span class="na"&gt;Type&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;simple&lt;/span&gt;
&lt;span class="na"&gt;Nice&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;19&lt;/span&gt;
&lt;span class="na"&gt;IOSchedulingClass&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;2&lt;/span&gt;
&lt;span class="na"&gt;IOSchedulingPriority&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;7&lt;/span&gt;
&lt;span class="na"&gt;ExecStart&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;/root/system-backup.sh&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Start and enable the timer:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;sudo systemctl start system-backup.timer
&lt;span class="nv"&gt;$ &lt;/span&gt;sudo systemctl &lt;span class="nb"&gt;enable &lt;/span&gt;system-backup.timer
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Starting the timer is necessary because otherwise it wouldn't be active until the next time you rebooted (assuming it was enabled, that is). You can verify that the timer has been started using either of the following commands:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;sudo systemctl status system-backup.timer
&lt;span class="nv"&gt;$ &lt;/span&gt;sudo systemctl list-timers --all
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;What this gets you&lt;/h2&gt;
&lt;p&gt;Using &lt;code&gt;OnCalendar=daily&lt;/code&gt; this job will run every day at midnight, similar to cron's &lt;code&gt;@daily&lt;/code&gt; keyword. If you ever want to run the job manually you can invoke its service on demand:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;sudo systemctl start system-backup.service
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Unless you're handling stdout manually in your script (like appending to a log file), any output from will go to the systemd journal. You can see the logs just like you'd do for any other system unit file using &lt;code&gt;journalctl&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;For example, to see logs from this timer since yesterday:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;sudo journalctl -u system-backup --since&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;yesterday&amp;quot;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I find this much more elegant than appending to, looking through, and rotating log files manually. Furthermore, I like the ability to set CPU and I/O scheduling priorities in the service itself rather than relying on external &lt;code&gt;nice&lt;/code&gt; and &lt;code&gt;ionice&lt;/code&gt; binaries in the script. :)&lt;/p&gt;
&lt;h2&gt;More information&lt;/h2&gt;
&lt;p&gt;See the following for more information:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;code&gt;man systemd.timer&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;man systemd.service&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;&lt;code&gt;man journalctl&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This was &lt;a href="https://mjanja.ch/2015/06/replacing-cron-jobs-with-systemd-timers/"&gt;originally posted&lt;/a&gt; on my personal blog; re-posted here for posterity.&lt;/p&gt;</summary><category term="linux"></category><category term="systemd"></category><category term="cron"></category></entry><entry><title>BRCK in violation of the GPL</title><link href="https://nairobilug.or.ke/2015/05/brck-violating-gpl.html" rel="alternate"></link><updated>2015-05-18T15:21:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2015-05-18:2015/05/brck-violating-gpl.html</id><summary type="html">&lt;p&gt;During a recent meeting of the Nairobi GNU/Linux Users Group we discussed &lt;a href="https://www.brck.com" title="BRCK | Rugged, Portable WiFi Hotspot &amp;amp; Battery Extender"&gt;BRCK&lt;/a&gt;, the Kenya-based makers of a slick, "rugged", battery-powered-GSM-router thing of the same name, and their apparent violation of the GNU General
Public License (GPL). The lively discussion ended up making its way to the web in the form of a &lt;a href="https://nairobilug.or.ke/2015/05/meetup-may-2015.html"&gt;blog
post&lt;/a&gt; on the group's blog.&lt;/p&gt;
&lt;p&gt;Their product is based on &lt;a href="https://openwrt.org/"&gt;OpenWRT&lt;/a&gt; — the GNU/Linux distribution geared towards embedded systems — which is &lt;a href="http://wiki.openwrt.org/about/license"&gt;licensed&lt;/a&gt; under the GPL v2. I believe this is problematic for BRCK for a number of reasons that I will enumerate below. When we reached out to BRCK they claimed that they were not in violation because they use "stock unmodified OpenWRT" source code. This claim is repeated verbatim in a &lt;a href="http://forums.brck.com/t/where-is-the-openwrt-fork-source-at/482/8"&gt;thread on their forum&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;I had intended this post to be a discussion of the spirit of the GPL ending with me expressing disappointment in BRCK for cowering behind perceived technicalities of the license. After sitting down to read the license, however, it became immediately apparent to me that they are indeed in violation. &lt;em&gt;*sigh*&lt;/em&gt;&lt;/p&gt;
&lt;h2&gt;The GNU General Public License&lt;/h2&gt;
&lt;p&gt;I'll save the discussion about the spirit of the GPL for later, but here's the gist:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;[...] if you distribute copies of such a program, whether gratis or
for a fee, you must give the recipients all the rights that you have.
You must make sure that they, too, receive or can get the source code.
And you must show them these terms so they know their rights.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;That's from the preamble of the &lt;a href="https://www.gnu.org/licenses/gpl2.txt"&gt;GPL Version 2&lt;/a&gt;. The license goes on to outline the terms and conditions for copying, distribution and modification.&lt;/p&gt;
&lt;p&gt;After several readings of the text it is my opinion that BRCK is &lt;em&gt;in violation of Sections 1, 2, and 3&lt;/em&gt; of the GPL v2 and that &lt;em&gt;their rights to distribute OpenWRT-derived works should be terminated under Section 4&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;My analysis follows.&lt;/p&gt;
&lt;h3&gt;Section 1&lt;/h3&gt;
&lt;p&gt;Section 1 deals with the distribution of source code. Specifically:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;You may copy and distribute verbatim copies of the Program's source
code as you receive it, in any medium, provided that you conspicuously
and appropriately publish on each copy an appropriate copyright notice
and disclaimer of warranty; keep intact all the notices that refer to
this License and to the absence of any warranty; and give any other
recipients of the Program a copy of this License along with the
Program.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;This is very important because compliance with Section 1 is required by subsequent Sections of the license. Use of the language "&lt;em&gt;may copy&lt;/em&gt;" merely grants BRCK the permission to distribute program source code which is explicitly required by Sections 2 and 3. In addition, Section 1 states that the copyright notice and license from the original work must be preserved.&lt;/p&gt;
&lt;p&gt;While BRCK does not provide source code for their work, they do offer public &lt;a href="https://www.brck.com/firmware/"&gt;downloads of their firmware binaries&lt;/a&gt;. Unfortunately there is neither a &lt;code&gt;LICENSE.txt&lt;/code&gt; file nor any mention of the the GPL in the archive provided:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;ls -l brckv1_20141114.zip
-rw-r----- &lt;span class="m"&gt;1&lt;/span&gt; aorth staff &lt;span class="m"&gt;5547580&lt;/span&gt; May &lt;span class="m"&gt;17&lt;/span&gt; 14:01 brckv1_20141114.zip
&lt;span class="nv"&gt;$ &lt;/span&gt;shasum brckv1_20141114.zip
d6dcbb1d61e99bf2b35133c5e6897a352518da0c  brckv1_20141114.zip
&lt;span class="nv"&gt;$ &lt;/span&gt;unzip brckv1_20141114.zip
&lt;span class="nv"&gt;$ &lt;/span&gt;grep -r -E &lt;span class="s1"&gt;&amp;#39;gpl|GPL&amp;#39;&lt;/span&gt; brckv1_20141114/* &lt;span class="p"&gt;|&lt;/span&gt; wc -l
       0
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;code&gt;brckv1_20141114.zip&lt;/code&gt; was retrieved on May 17, 2015 and had the file size and SHA1 fingerprint shown above.&lt;/p&gt;
&lt;h3&gt;Section 2&lt;/h3&gt;
&lt;p&gt;Section 2 deals with modifications to the program. Specifically:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;a) You must cause the modified files to carry prominent notices
stating that you changed the files and the date of any change.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;At first this Section doesn't seem to apply, as BRCK claims to be using "stock unmodified OpenWRT", but I find their claim dubious for two reasons:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;The OpenWRT project doesn't provide source code producing firmware for any device called "BRCK", so it is unclear from which source code the firmware builds are created.&lt;/li&gt;
&lt;li&gt;BRCK themselves allude to "optimizing" for a 4MB image size, which implies modification.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Nevertheless, if BRCK does indeed use "stock unmodified OpenWRT" source code then the &lt;a href="https://www.kernel.org/doc/pending/gplv2-howto.html"&gt;Linux kernel's GPL v2 compliance guide&lt;/a&gt; suggests:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;The minimum sufficient answer includes the version number, whether or
not it was modified, and where we can get it from. I.E. something
like: "We used Linux 2.6.22.4, from www.kernel.org, and we didn't
modify it." If you didn't modify a package, say so. Even when you used
unmodified source code, the GPL requires you to _identify_ the
source code you used, clearly and explicitly, at least in response to
direct questions about it.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;One &lt;a href="https://copyleft.org/guide/comprehensive-gpl-guidech6.html"&gt;popular interpretation&lt;/a&gt; of the GPL v2 states that Section 2 "&lt;em&gt;[...] seeks to ensure that those receiving modified versions know the history of changes to the software.&lt;/em&gt;"&lt;/p&gt;
&lt;p&gt;As BRCK neither publishes the corresponding source code for their modified binaries, nor explicitly states the exact "unmodified" versions used, they are in clear violation of Section 2.&lt;/p&gt;
&lt;h3&gt;Section 3&lt;/h3&gt;
&lt;p&gt;Section 3 deals with the distribution of derived works in object code or executable form. Specifically:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;a) Accompany it with the complete corresponding machine-readable
source code, which must be distributed under the terms of Sections 1
and 2 above&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It goes on to state:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;For an executable work, complete source code means all the source code
for all modules it contains, plus any associated interface definition
files, plus the scripts used to control compilation and installation
of the executable.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Not only does BRCK need to provide the complete source code for their OpenWRT-derived work itself, they need to provide the bits used to produce their firmware builds &lt;em&gt;from&lt;/em&gt; that source code.&lt;/p&gt;
&lt;h3&gt;Sections 4 and 5&lt;/h3&gt;
&lt;p&gt;Section 5 stipulates implicit acceptance of the license terms upon distribution of the work, and Section 4 is crystal clear on the termination of the rights in case of non-compliance:&lt;/p&gt;
&lt;blockquote&gt;
&lt;ol&gt;
&lt;li&gt;You may not copy, modify, sublicense, or distribute the Program
except as expressly provided under this License. Any attempt otherwise
to copy, modify, sublicense or distribute the Program is void, and
will automatically terminate your rights under this License. [...]&lt;/li&gt;
&lt;/ol&gt;
&lt;/blockquote&gt;
&lt;p&gt;By my reading this means BRCK's rights to distribute OpenWRT-derived works are void.&lt;/p&gt;
&lt;h2&gt;Compliance&lt;/h2&gt;
&lt;p&gt;Interpretation of the license is a bit confusing at first, but very accessible if you actually read it. Put simply: copyleft obligations of the GPL v2 are triggered upon &lt;em&gt;distribution&lt;/em&gt; of binary works derived from a GPL-licensed program.&lt;/p&gt;
&lt;p&gt;As BRCK is distributing an OpenWRT-derived work in object code form, Section 3 requires that they provide &lt;em&gt;complete corresponding machine-readable source code&lt;/em&gt; used to produce the object code they are distributing. Section 1 grants them the permission to provide this code and stipulates that it must preserve the copyright notice and license of the original work.&lt;/p&gt;
&lt;p&gt;The implications of Section 2 are less clear, depending on whether or not BRCK is actually using "stock unmodified OpenWRT" source code. I suppose that's up to them to decide, but I would urge them to keep in mind the spirit of the GPL v2 when making that decision.&lt;/p&gt;
&lt;h2&gt;BRCK should know better&lt;/h2&gt;
&lt;p&gt;BRCK is not the "enemy", but they — of all people — should know better. We expect this behavior from large corporations, but not from quasi-community-based organizations operating in the technical sector.&lt;/p&gt;
&lt;p&gt;In the end none of this matters unless someone is willing to take BRCK to court over non-compliance. Even if someone was willing to do so, I think it would be sad if it had to come to that. Instead, I hope this serves as a lesson in GPL v2 compliance for Kenyan organizations in the future, and indeed a public record of my findings.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Update (2015-05-19):&lt;/strong&gt; BRCK has &lt;a href="http://forums.brck.com/t/where-is-the-openwrt-fork-source-at/482/11"&gt;responded&lt;/a&gt; and posted &lt;a href="https://www.brck.com/open-source-compliance/"&gt;licensing information and source code&lt;/a&gt; on their website.&lt;/p&gt;
&lt;p&gt;This was &lt;a href="https://mjanja.ch/2015/05/brck-in-violation-of-the-gpl/"&gt;originally posted&lt;/a&gt; on my personal blog; re-posted here for posterity.&lt;/p&gt;</summary><category term="licensing"></category><category term="gpl"></category></entry><entry><title>Meetup Summary (May, 2015)</title><link href="https://nairobilug.or.ke/2015/05/meetup-may-2015.html" rel="alternate"></link><updated>2015-05-10T17:25:00+03:00</updated><author><name>Jason Rogena</name></author><id>tag:nairobilug.or.ke,2015-05-10:2015/05/meetup-may-2015.html</id><summary type="html">&lt;p&gt;Just like most months, we had the monthly meetup at KFC Kimathi on the first Saturday (2nd May). Eight people showed up.&lt;/p&gt;
&lt;h3&gt;Topics Discussed&lt;/h3&gt;
&lt;p&gt;A lot was discussed. Opera Mini, and whether the Nairobi LUG blog should be accessible using this browser, Search Engine Optimization, learning Rust.. I'm not going to pretend I remember everything that was discussed, partly because I'm writing this one week later.&lt;/p&gt;
&lt;h3&gt;GPL Violation&lt;/h3&gt;
&lt;p&gt;One topic that was discussed that I feel like I need to highlight is the &lt;a href="https://www.gnu.org/copyleft/gpl.html"&gt;GPL&lt;/a&gt; and how some Kenyan companies are violating it. &lt;a href="https://www.brck.com/"&gt;BRCK&lt;/a&gt;, for instance, runs a fork of &lt;a href="https://openwrt.org/"&gt;OpenWRT&lt;/a&gt; yet NONE of its code is open (at least the forked OpenWRT code should be). OpenWRT is a GNU Linux distribution that comprises of at least two high profile projects (the &lt;a href="https://kernel.org/"&gt;Linux kernel&lt;/a&gt; and &lt;a href="http://www.busybox.net/"&gt;BusyBox&lt;/a&gt;) that are licensed under the GPL. All projects that are derivatives of OpenWRT therefore are technically licensed under the GPL. I reached out to the BRCK team but I still haven't gotten a response from them. It's time 'they' know we are not fine with them violating the GPL!&lt;/p&gt;
&lt;p&gt;VIVA GPL!!&lt;/p&gt;</summary><category term="KFC"></category><category term="meetup"></category></entry><entry><title>Simultaneously pushing to two remotes in a git repository</title><link href="https://nairobilug.or.ke/2015/05/pushing-two-git-remotes.html" rel="alternate"></link><updated>2015-05-10T16:40:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2015-05-10:2015/05/pushing-two-git-remotes.html</id><summary type="html">&lt;p&gt;Sometimes you need to push commits to two remotes in a git repository — either for a cheap "backup" of sorts, or for some public / private repository scheme you may have in your organization, etc.&lt;/p&gt;
&lt;p&gt;Let's say you have a repository hosted on GitHub &lt;em&gt;and&lt;/em&gt; BitBucket (hey, GitHub is king today, but you never know!). You could add a remote for each and push to them individually:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;git push github
&lt;span class="nv"&gt;$ &lt;/span&gt;git push bitbucket
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This works fine but it's a bit manual. Also, assuming you want both remotes to essentially be mirrors of each other, there's a better way.&lt;/p&gt;
&lt;h3&gt;A better way&lt;/h3&gt;
&lt;p&gt;If you're using any relatively modern version of git (1.9?) you can manipulate the remote to include two push URLs. Instead of adding a second remote, you simply add a second push URL to the existing remote.&lt;/p&gt;
&lt;p&gt;For example, adding a BitBucket URL to the remote called "origin":&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;git remote &lt;span class="nb"&gt;set&lt;/span&gt;-url origin --add git@bitbucket.org:alanorth/repo.git
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After that the remote looks like this:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;git remote -v
origin  git@github.com:alanorth/repo.git &lt;span class="o"&gt;(&lt;/span&gt;fetch&lt;span class="o"&gt;)&lt;/span&gt;
origin  git@github.com:alanorth/repo.git &lt;span class="o"&gt;(&lt;/span&gt;push&lt;span class="o"&gt;)&lt;/span&gt;
origin  git@bitbucket.org:alanorth/repo.git &lt;span class="o"&gt;(&lt;/span&gt;push&lt;span class="o"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Now there are two push URLs, so every time you push it will go to both remotes, while pull or update operations will only come from the URL labeled "fetch".&lt;/p&gt;
&lt;p&gt;You're welcome. ;)&lt;/p&gt;
&lt;p&gt;This was &lt;a href="https://mjanja.ch/2015/05/simultaneously-pushing-to-two-remotes-in-a-git-repository/"&gt;originally posted&lt;/a&gt; on my personal blog; re-posted here for posterity.&lt;/p&gt;</summary><category term="linux"></category><category term="git"></category></entry><entry><title>Ramping up the Ethiopia LUG</title><link href="https://nairobilug.or.ke/2015/04/ramping-up-ethiopia-lug.html" rel="alternate"></link><updated>2015-04-25T21:01:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2015-04-25:2015/04/ramping-up-ethiopia-lug.html</id><summary type="html">&lt;p&gt;Today I had the pleasure of participating in a rare meeting of the Ethiopia GNU/Linux Users Group at the &lt;a href="http://www.iceaddis.com"&gt;iceaddis&lt;/a&gt; co-working space in Addis Ababa. In all the years I've lived in Kenya, and all the times I've been to Ethiopia, I've never heard anything about Linux or open-source software groups in the community. But alas, they do exist! I enlisted the help of some friends in Addis and planned to arrange a meeting the next time I went to Ethiopia.&lt;/p&gt;
&lt;p&gt;Much to my surprise the Linux Users Group has been in existence for a few years, and even has a fairly active &lt;a href="https://groups.google.com/forum/#!forum/linux-ethiopia"&gt;mailing list&lt;/a&gt; (albeit a bit off topic!). The list is active enough that, when we sent word of the meeting, several people replied stating interest and one actually showed up to the meeting!&lt;/p&gt;
&lt;p&gt;The meeting was small, short, and sweet. In addition to our one Internet person, I brought a few of my Addis friends and colleagues. Seven people taking time out of their Saturday to talk about free, libre, open-source software and community. Not a bad start!&lt;/p&gt;
&lt;h3&gt;A good start&lt;/h3&gt;
&lt;p&gt;I opened the meeting by giving a brief background of the Nairobi GNU/Linux Users Group; from a few of us trading hashtags on Twitter to regular monthly meetings, an active &lt;a href="https://groups.google.com/forum/#!forum/nairobi-gnu"&gt;mailing list&lt;/a&gt;, &lt;a href="https://kiwiirc.com/client/irc.freenode.net/#nairobilug"&gt;lively IRC channel&lt;/a&gt;, &lt;a href="https://github.com/nairobilug/nairobilug.or.ke"&gt;democratically managed website&lt;/a&gt;, etc. On second thought it wasn't very brief, but I'm sure it was entertaining and insightful. ;)&lt;/p&gt;
&lt;p&gt;We talked about some ways to ramp up the group:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Networking with other groups like &lt;a href="https://ubuntu-za.org"&gt;Ubuntu ZA&lt;/a&gt; and &lt;a href="http://www.linux.or.ug"&gt;Uganda LUG&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Different formats for users group meetings, like alternating between informal and giving presentations&lt;/li&gt;
&lt;li&gt;Raising the profile of Linux and free, libre, open-source software in Ethiopia&lt;/li&gt;
&lt;li&gt;Creating a community of people with common interests who can tip each other off about job opportunities, go rafting down the Nile together, recommend books to each other, etc (seriously!)&lt;/li&gt;
&lt;li&gt;Relationships with other users groups in Addis, like the &lt;a href="https://addis.meteor.com"&gt;Meteor.js group&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Generally, I drew parallels between the early days of the Nairobi GNU/Linux Users Group and the current state of the Ethiopian group in Addis. My advice was for them to create a website and draw on social media to drive users to their mailing list to keep discussions going.&lt;/p&gt;
&lt;h3&gt;Eyob's GitHub shirt&lt;/h3&gt;
&lt;p&gt;Here's a shoutout to Eyob, who saw the message on the mailing list and bothered to show up. I had brought a GitHub shirt with me to give out and it just seemed right to give it to him!&lt;/p&gt;
&lt;p&gt;&lt;img alt="Eyob with his new GitHub shirt" src="/images/addis-meetup-2015-04-25.jpg" title="Eyob with his new GitHub shirt" /&gt;&lt;/p&gt;
&lt;p&gt;Hopefully that's motivation for people to show up to meetings from time to time! Also, I think he might be the first one in Addis with a GitHub shirt. w00t?&lt;/p&gt;
&lt;h3&gt;Linux users' couches&lt;/h3&gt;
&lt;p&gt;I joked that I'd like to be able to take a road trip from Addis to Cape Town and sleep on Linux users' couches in cities all along the way. It's a bit of an oversimplification, but the point is that we're building networks. Whether you're looking for help on your Ubuntu machine, trying to find potential employees to manage your servers, or just need a place to sleep in Pretoria, we are building networks to connect people.&lt;/p&gt;
&lt;p&gt;Thanks to everyone that came to the meeting. Stay tuned for the next one! So long, and thanks for all the ቡና!&lt;/p&gt;</summary><category term="meetup"></category></entry><entry><title>Rebooting server(s) using Ansible</title><link href="https://nairobilug.or.ke/2015/03/rebooting-server-using-ansible.html" rel="alternate"></link><updated>2015-03-03T12:35:00+03:00</updated><author><name>James Oguya</name></author><id>tag:nairobilug.or.ke,2015-03-03:2015/03/rebooting-server-using-ansible.html</id><summary type="html">&lt;p&gt;In this blogpost, we'll talk about rebooting servers using ansible &amp;amp; pausing the
playbook by waiting for a given amount of time for a given service on a given
port to start.&lt;/p&gt;
&lt;p&gt;Of late, I've seen a lot of guys on &lt;code&gt;#ansible&lt;/code&gt; irc channel &amp;amp; google groups
asking questions about rebooting servers/nodes &amp;amp; temporarily pausing the
playbook for a given amount of time before continuing with the execution of the
playbook. In some cases, you'd want to set some kernel parameters which take
effect at boot time or perform major upgrades which might require a reboot
before configuring the server/node.&lt;/p&gt;
&lt;p&gt;Using ansible's &lt;code&gt;wait_for&lt;/code&gt; module&lt;a href="http://docs.ansible.com/wait_for_module.html"&gt;&lt;sup&gt;[1]&lt;/sup&gt;&lt;/a&gt;,
we can temporarily stop running the playbook while we wait for the server to
finish rebooting or for a service to start &amp;amp; bind to a port. We can also use the
same module to wait for a port to become available which can be useful in
situations where services are not immediately available after their &lt;code&gt;init&lt;/code&gt;
scripts finish running - as is the case with Java application server e.g. Tomcat.&lt;/p&gt;
&lt;h3&gt;gettin' started&lt;/h3&gt;
&lt;p&gt;Basically, we can break our problem into 4 sections for easier conceptualization:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Section 1: &lt;strong&gt;Pre-reboot&lt;/strong&gt;: Run your pre-reboot task, it can be performing major
upgrades and/or performing some configuration which only take effect at boot time.
For example - upgrade all packages using &lt;code&gt;yum&lt;/code&gt; module&lt;a href="http://docs.ansible.com/yum_module.html"&gt;&lt;sup&gt;[2]&lt;/sup&gt;&lt;/a&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;- name: upgrade all packages
  yum: name=* state=latest
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Section 2: &lt;strong&gt;Reboot&lt;/strong&gt;: In this stage we'll use the &lt;code&gt;command&lt;/code&gt; module&lt;a href="http://docs.ansible.com/command_module.html"&gt;&lt;sup&gt;[3]&lt;/sup&gt;&lt;/a&gt;
to reboot the remote machine/server by running the &lt;code&gt;reboot&lt;/code&gt; command  - nothing
fancy - you can also use &lt;code&gt;shutdown --reboot&lt;/code&gt;.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;- name: reboot server
  command: /sbin/reboot
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Section 3: &lt;strong&gt;Pause the playbook&lt;/strong&gt;: We'll use the &lt;code&gt;wait_for&lt;/code&gt; module to wait for
300 seconds for port 22 to become available before resuming the playbook. I'm
using port 22 because most servers run openssh-server on port 22 &amp;amp; if we were to
telnet to that port we'd probably see something like :&lt;code&gt;SSH-2.0-OpenSSH_6.6.1&lt;/code&gt;,
so we can use regex to check whether the output matches "OpenSSH". I'm also
using a &lt;code&gt;timeout&lt;/code&gt; value of 300 seconds because most physical servers take
3 - 5 minutes to finish rebooting due to hardware checks e.t.c. but you can
use any value that suites you.
For example: - wait for 300 seconds for port 22 to become available &amp;amp; contain
&lt;code&gt;OpenSSH&lt;/code&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;- name: wait for the server to finish rebooting
  local_action: wait_for host=&amp;quot;web01&amp;quot; search_regex=OpenSSH port=22 timeout=300
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Section 4: &lt;strong&gt;Resume the playbook&lt;/strong&gt;: After we've got a response from port 22,
we can resume running the playbook. This step can be optional depending on your
needs.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;puttin' it all together&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;We can merge all the above sections into one playbook as shown below:&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;- hosts: all&lt;/span&gt;
&lt;span class="x"&gt;  sudo: yes&lt;/span&gt;
&lt;span class="x"&gt;  tasks:&lt;/span&gt;
&lt;span class="x"&gt;    - name: Upgrade all packages in RedHat-based machines&lt;/span&gt;
&lt;span class="x"&gt;      when: ansible_os_family == &amp;quot;Redhat&amp;quot;&lt;/span&gt;
&lt;span class="x"&gt;      yum: name=* state=latest&lt;/span&gt;

&lt;span class="x"&gt;    - name: Upgrade all packages in Debian-based machines&lt;/span&gt;
&lt;span class="x"&gt;      when: ansible_os_family == &amp;quot;Debian&amp;quot;&lt;/span&gt;
&lt;span class="x"&gt;      apt: upgrade=dist update_cache=yes&lt;/span&gt;

&lt;span class="x"&gt;    - name: Reboot server&lt;/span&gt;
&lt;span class="x"&gt;      command: /sbin/reboot&lt;/span&gt;

&lt;span class="x"&gt;    - name: Wait for the server to finish rebooting&lt;/span&gt;
&lt;span class="x"&gt;      sudo: no&lt;/span&gt;
&lt;span class="x"&gt;      local_action: wait_for host=&amp;quot;&lt;/span&gt;&lt;span class="cp"&gt;{{&lt;/span&gt; &lt;span class="nv"&gt;inventory_hostname&lt;/span&gt; &lt;span class="cp"&gt;}}&lt;/span&gt;&lt;span class="x"&gt;&amp;quot; search_regex=OpenSSH port=22 timeout=300&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;stuff to note&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;I know you might be wondering why we didn't use handlers. Well, &lt;code&gt;notify&lt;/code&gt;
tasks&lt;a href="http://docs.ansible.com/playbooks_intro.html#handlers-running-operations-on-change"&gt;&lt;sup&gt;[4]&lt;/sup&gt;&lt;/a&gt;
are only executed at the end of the playbook regardless of their location in the
playbook - remember we're interested in rebooting the server &amp;amp; waiting for a
given amount of time for the server to finish rebooting.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;inventory_hostname&lt;/code&gt; variable&lt;a href="http://docs.ansible.com/playbooks_variables.html#magic-variables-and-how-to-access-information-about-other-hosts"&gt;&lt;sup&gt;[5]&lt;/sup&gt;&lt;/a&gt;
is the name of the remote server as stated in
the ansible hosts file&lt;/li&gt;
&lt;li&gt;&lt;code&gt;local_action&lt;/code&gt; directive&lt;a href="http://docs.ansible.com/glossary.html#local-action"&gt;&lt;sup&gt;[6]&lt;/sup&gt;&lt;/a&gt;
runs the given step on the local machine, for example, it would run the
&lt;code&gt;wait_for&lt;/code&gt; task on your local machine.&lt;/li&gt;
&lt;li&gt;&lt;code&gt;yum&lt;/code&gt; module only works on RedHat based OS e.g. Fedora, CentOS &amp;amp; RHEL -
and so we'll also use the &lt;code&gt;apt&lt;/code&gt; module for Debian based OS e.g. Ubuntu, Debian
e.t.c.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;links&lt;/h3&gt;
&lt;ol&gt;
&lt;li&gt;&lt;a href="http://docs.ansible.com/wait_for_module.html"&gt;Ansible wait_for module&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.ansible.com/command_module.html"&gt;Ansible command module&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.ansible.com/yum_module.html"&gt;Ansible yum module&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.ansible.com/playbooks_intro.html#handlers-running-operations-on-change"&gt;Ansible Handlers: Running operations on change&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.ansible.com/playbooks_variables.html#magic-variables-and-how-to-access-information-about-other-hosts"&gt;Playbook built-in variables&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.ansible.com/glossary.html#local-action"&gt;Ansible local_action directives&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</summary><category term="linux"></category><category term="ansible"></category></entry><entry><title>Meetup Summary (February, 2015)</title><link href="https://nairobilug.or.ke/2015/02/meetup-february-2015.html" rel="alternate"></link><updated>2015-02-07T16:30:00+03:00</updated><author><name>Alois Mbutura</name></author><id>tag:nairobilug.or.ke,2015-02-07:2015/02/meetup-february-2015.html</id><summary type="html">&lt;p&gt;Twenty people showed up, and as always some people were late, others were not. A few new people (ahem, Frank!), and others not as new whom I had not seen for a while. Big special shoutout to Maureiq, the only female member in the meetup.&lt;/p&gt;
&lt;h3&gt;As it happened, insider info&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;There was talk that everyone should try to watch the movie &lt;a href="http://www.imdb.com/title/tt4044364"&gt;Citizenfour&lt;/a&gt; -- an eye opening documentary on privacy, surveillance and obviously the bigger picture.&lt;/li&gt;
&lt;li&gt;Jason talked of making an open source platform -- ma3map &lt;a href="https://github.com/ma3map/ma3map-client_android"&gt;client&lt;/a&gt; and &lt;a href="https://github.com/ma3map/ma3map-server"&gt;server&lt;/a&gt; -- for doing route interconnection and using machine learning to decide how to effectively recommend which matatus to take (and in which order).&lt;/li&gt;
&lt;li&gt;Alan mentioned that the reason that Mozilla Firefox (or any other browser) has been so slow in the last few years is &lt;a href="https://blog.mozilla.org/nnethercote/2014/05/14/adblock-pluss-effect-on-firefoxs-memory-usage"&gt;likely due to everyone using the AdBlock Plus add-on&lt;/a&gt;, and suggested people switch to &lt;a href="https://github.com/gorhill/uBlock"&gt;µBlock&lt;/a&gt;. µBlock uses up to &lt;a href="https://github.com/gorhill/uBlock/wiki/%C2%B5Block-vs.-ABP:-efficiency-compared"&gt;two or three times less RAM&lt;/a&gt; than AdBlock Plus on both Firefox and Chrome.&lt;/li&gt;
&lt;li&gt;Lots of other questions, laughs and more.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is my first time posting so if I may have ommitted anything important, feel free to alter my &lt;a href="https://github.com/nairobilug/nairobilug.or.ke"&gt;post&lt;/a&gt; and then make a pull request. Big thanks to all the people who taught me &lt;a href="https://github.com/adam-p/markdown-here/wiki/Markdown-Here-Cheatsheet#links"&gt;Markdown&lt;/a&gt;... without which this post wouldn't have been possible.&lt;/p&gt;
&lt;h3&gt;Next time&lt;/h3&gt;
&lt;p&gt;See you all on March 7th. Meetups are usually on the first Saturday of every month at KFC, Kimathi street at 16:30. Bring a friend!&lt;/p&gt;</summary><category term="KFC"></category><category term="meetup"></category></entry><entry><title>Leveraging the Ansible Python API for infrastructure reporting</title><link href="https://nairobilug.or.ke/2015/01/ansible-api-reporting.html" rel="alternate"></link><updated>2015-01-21T16:40:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2015-01-21:2015/01/ansible-api-reporting.html</id><summary type="html">&lt;p&gt;A few days ago I had to get some basic information from a handful of servers for an inventory report; just basic stuff like hostname, IP address, storage capacity, distro version, etc. I already manage all of my servers with Ansible, and there's a wealth of information available in Ansible's &lt;code&gt;setup&lt;/code&gt; module, so I knew there had to be a clever way to do this.&lt;/p&gt;
&lt;p&gt;Somehow I stumbled upon &lt;a href="http://docs.ansible.com/developing_api.html"&gt;Ansible's Python API&lt;/a&gt;, which solves this problem elegantly! It helped that other people are doing cool things and &lt;a href="http://jpmens.net/2012/12/13/obtaining-remote-data-with-ansible-s-api/"&gt;writing about their experiences&lt;/a&gt; too.&lt;/p&gt;
&lt;h2&gt;Enter ansible.runner&lt;/h2&gt;
&lt;p&gt;According to the documentation, the Python API is:
&lt;blockquote&gt;[...] very powerful, and is how the ansible CLI and ansible-playbook are implemented.&lt;/blockquote&gt;&lt;/p&gt;
&lt;p&gt;Indeed! Using &lt;code&gt;ansible.runner&lt;/code&gt; I whipped something up and extracted data from several dozen servers in just a few minutes (and I don't even know Python!):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;./ansible-runner.py
mjanjavm10, 2, 30, Ubuntu 14.04, 192.168.7.34
mjanjavm14, 2, 30, Ubuntu 14.04, 192.168.7.37
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;I had to massage the data a bit to get clean numbers for RAM and storage capacity, but other than that it was extremely straightforward (as most things with Ansible generally are).&lt;/p&gt;
&lt;h2&gt;The code&lt;/h2&gt;
&lt;p&gt;Here's the source code for the &lt;em&gt;ansible-runner.py&lt;/em&gt; script above:&lt;/p&gt;
&lt;table class="highlighttable"&gt;&lt;tr&gt;&lt;td class="linenos"&gt;&lt;div class="linenodiv"&gt;&lt;pre&gt; 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
27
28
29
30
31
32
33
34
35
36
37
38
39
40
41
42
43
44
45
46
47
48
49
50&lt;/pre&gt;&lt;/div&gt;&lt;/td&gt;&lt;td class="code"&gt;&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/usr/bin/env python&lt;/span&gt;

&lt;span class="kn"&gt;import&lt;/span&gt; &lt;span class="nn"&gt;ansible.runner&lt;/span&gt;

&lt;span class="c"&gt;# hosts to contact&lt;/span&gt;
&lt;span class="n"&gt;hostlist&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;virtual&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;

&lt;span class="c"&gt;# MiB -&amp;gt; GiB&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;mibs_to_gibs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mibs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;mibs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;1024.0&lt;/span&gt;

&lt;span class="c"&gt;# KiB -&amp;gt; GiB&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;kibs_to_gibs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kibs&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;kibs&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;1024.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;1024.0&lt;/span&gt;

&lt;span class="c"&gt;# bytes -&amp;gt; GiB&lt;/span&gt;
&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;bytes_to_gibs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_bytes&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;return&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;num_bytes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;1024.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;1024.0&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="mf"&gt;1024.0&lt;/span&gt;

&lt;span class="k"&gt;def&lt;/span&gt; &lt;span class="nf"&gt;parse_results&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;):&lt;/span&gt;
    &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hostname&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;contacted&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;items&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
        &lt;span class="n"&gt;memory&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;mibs_to_gibs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ansible_facts&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ansible_memtotal_mb&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

        &lt;span class="c"&gt;# enumerate all disk devices to get total capacity&lt;/span&gt;
        &lt;span class="n"&gt;disk_total_capacity&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="mi"&gt;0&lt;/span&gt;
        &lt;span class="k"&gt;for&lt;/span&gt; &lt;span class="n"&gt;disk_device&lt;/span&gt; &lt;span class="ow"&gt;in&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ansible_facts&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ansible_devices&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;]&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;iterkeys&lt;/span&gt;&lt;span class="p"&gt;():&lt;/span&gt;
            &lt;span class="n"&gt;disk_sectors&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ansible_facts&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ansible_devices&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;disk_device&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sectors&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;disk_sectors_size&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="nb"&gt;float&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ansible_facts&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ansible_devices&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="n"&gt;disk_device&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;sectorsize&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
            &lt;span class="n"&gt;disk_bytes&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;disk_sectors&lt;/span&gt; &lt;span class="o"&gt;*&lt;/span&gt; &lt;span class="n"&gt;disk_sectors_size&lt;/span&gt;

            &lt;span class="n"&gt;disk_total_capacity&lt;/span&gt; &lt;span class="o"&gt;+=&lt;/span&gt; &lt;span class="n"&gt;bytes_to_gibs&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;disk_bytes&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

        &lt;span class="n"&gt;os&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt; &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ansible_facts&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ansible_distribution&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ansible_facts&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ansible_distribution_version&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;
        &lt;span class="n"&gt;ip&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;result&lt;/span&gt;&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ansible_facts&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;ansible_default_ipv4&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;][&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;address&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;])&lt;/span&gt;

        &lt;span class="k"&gt;print&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;&lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;, &lt;/span&gt;&lt;span class="si"&gt;%.0f&lt;/span&gt;&lt;span class="s"&gt;, &lt;/span&gt;&lt;span class="si"&gt;%2.0f&lt;/span&gt;&lt;span class="s"&gt;, &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;, &lt;/span&gt;&lt;span class="si"&gt;%s&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;&lt;/span&gt; &lt;span class="o"&gt;%&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;hostname&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;memory&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;disk_total_capacity&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;os&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="n"&gt;ip&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="k"&gt;if&lt;/span&gt; &lt;span class="n"&gt;__name__&lt;/span&gt; &lt;span class="o"&gt;==&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;__main__&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;:&lt;/span&gt;
    &lt;span class="n"&gt;results&lt;/span&gt; &lt;span class="o"&gt;=&lt;/span&gt; &lt;span class="n"&gt;ansible&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;runner&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;Runner&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;
        &lt;span class="n"&gt;module_name&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;setup&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;module_args&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;remote_user&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;provisioning&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;sudo&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="bp"&gt;False&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;pattern&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="n"&gt;hostlist&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
        &lt;span class="n"&gt;forks&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="mi"&gt;5&lt;/span&gt;
    &lt;span class="p"&gt;)&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="n"&gt;run&lt;/span&gt;&lt;span class="p"&gt;()&lt;/span&gt;

    &lt;span class="n"&gt;parse_results&lt;/span&gt;&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="n"&gt;results&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

&lt;span class="c"&gt;# vim: set sw=4 ts=4:&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;
&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;

&lt;p&gt;Feel free to use, improve, and share it.&lt;/p&gt;
&lt;p&gt;This was &lt;a href="https://mjanja.ch/2015/01/leveraging-the-ansible-python-api-for-infrastructure-reporting/"&gt;originally posted&lt;/a&gt; on my personal blog; re-posted here for posterity.&lt;/p&gt;</summary><category term="linux"></category><category term="ansible"></category></entry><entry><title>Meetup Summary (January, 2015)</title><link href="https://nairobilug.or.ke/2015/01/meetup-january-2015.html" rel="alternate"></link><updated>2015-01-19T20:40:00+03:00</updated><author><name>Njagi Mwaniki</name></author><id>tag:nairobilug.or.ke,2015-01-19:2015/01/meetup-january-2015.html</id><summary type="html">&lt;p&gt;First off the meetup couldn't be held on the usual first Saturday of the month (4-Jan-2015) but was held on the second Satruday (11-Jan-2015) because by Kenyan culture people just aren't around Nairobi until at least the first Monday after first January. This pushing forward of the meetup was discussed in the mailing list and it was agreed.&lt;/p&gt;
&lt;p&gt;The meetup was awesome. I had missed quite a number of them and so I met a lot of new faces. Almost everyone was new so I count for that as growth.&lt;/p&gt;
&lt;p&gt;Discussions:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;XMPP: We had agreed in the mailing list that we would talk about running an XMPP server for secure communication among members. Sadly this matter wasn't discussed as much as I hope it would have been. What I got is that everyone thought it was a good thing, just that we didn't agree on a when and where the hosting would be done and the source of funding.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Monetizing apps in Kenya. How to make something people want to pay for and get them to pay for it. People want to see some sort of proof of concept first they don't just buy in.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;poppingtonic and I talked about &lt;a href="http://mitpress.mit.edu/sicp/"&gt;SICP&lt;/a&gt; and some CS stuff, fun conversation.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;There was a lot of catching up being friends and such things.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;</summary><category term="KFC"></category><category term="meetup"></category></entry><entry><title>Ansible 'Prompt' Handlers</title><link href="https://nairobilug.or.ke/2015/01/ansible-prompt-handlers.html" rel="alternate"></link><updated>2015-01-02T11:00:00+03:00</updated><author><name>James Oguya</name></author><id>tag:nairobilug.or.ke,2015-01-02:2015/01/ansible-prompt-handlers.html</id><summary type="html">&lt;p&gt;An awesome feature in &lt;a href="https://chef.io"&gt;Chef&lt;/a&gt; that is not available in &lt;a href="http://ansible.com"&gt;Ansible&lt;/a&gt; is immediate notification i.e. &lt;code&gt;notifies :immediately&lt;/code&gt;.
Ansible has &lt;a href="http://docs.ansible.com/playbooks_intro.html#handlers-running-operations-on-change"&gt;notification handlers&lt;/a&gt; but they are only triggered at the end of the current playbook unlike &lt;a href="https://docs.chef.io/resource_common.html#notifies-syntax"&gt;Chef's notifications&lt;/a&gt; which can be triggered immediately! Moreover, you can configure Chef's notifications to be triggered at specific times e.g. at the very end of a chef-client run i.e. &lt;code&gt;notifies :delayed&lt;/code&gt; or immediately i.e. &lt;code&gt;notifies :immediately&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Now, why I'm going into all these boring theories? Well, when installing tomcat on Ubuntu, dpkg starts it automatically once the process is complete. But in my case, I wanted to stop tomcat7 service first, configure it, deploy its webapps &amp;amp; finally start it. So on my ansible tasks file, after installing tomcat7 I added a notification action to call a task that stops tomcat7 service. Here's a snippet from the ansible task file:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;tomcat.yml&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;- hosts: all&lt;/span&gt;
&lt;span class="x"&gt;  sudo: yes&lt;/span&gt;
&lt;span class="x"&gt;  tasks:&lt;/span&gt;
&lt;span class="x"&gt;    - name: Install tomcat7&lt;/span&gt;
&lt;span class="x"&gt;      apt: name=&lt;/span&gt;&lt;span class="cp"&gt;{{&lt;/span&gt; &lt;span class="nv"&gt;item&lt;/span&gt; &lt;span class="cp"&gt;}}&lt;/span&gt;&lt;span class="x"&gt; install_recommends=no update_cache=yes  state=present&lt;/span&gt;
&lt;span class="x"&gt;      with_items:&lt;/span&gt;
&lt;span class="x"&gt;        - tomcat7&lt;/span&gt;
&lt;span class="x"&gt;        - tomcat7-admin&lt;/span&gt;
&lt;span class="x"&gt;      notify:&lt;/span&gt;
&lt;span class="x"&gt;        - Temporarily stop tomcat7&lt;/span&gt;

&lt;span class="x"&gt;  handlers:&lt;/span&gt;
&lt;span class="x"&gt;      - name: Temporarily stop tomcat7&lt;/span&gt;
&lt;span class="x"&gt;      service: name=tomcat7 state=stopped&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;OK so the task file looks great, but did it work ? Unfortunately, no! Ansible notifications trigger tasks in handlers section to run only at the end of a playbook.
So I had to come up with a quick fix for this issue.&lt;/p&gt;
&lt;h3&gt;'Prompt' handlers&lt;/h3&gt;
&lt;p&gt;My quick fix involved registering a variable in the task that installs tomcat packages i.e. &lt;code&gt;register: tomcat_installed&lt;/code&gt;, then the next task to stop tomcat service would be executed only if the registered variable has changed i.e. if tomcat7 has been installed - &lt;code&gt;when: tomcat_installed|changed&lt;/code&gt;.
Basically, ansible notifications use a similar concept to this.&lt;/p&gt;
&lt;p&gt;Here's a snippet from the playbook showing the quick fix:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;tomcat.yml&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="x"&gt;- hosts: all&lt;/span&gt;
&lt;span class="x"&gt;  sudo: yes&lt;/span&gt;
&lt;span class="x"&gt;  tasks:&lt;/span&gt;
&lt;span class="x"&gt;      - name: Install tomcat7&lt;/span&gt;
&lt;span class="x"&gt;        apt: name=&lt;/span&gt;&lt;span class="cp"&gt;{{&lt;/span&gt; &lt;span class="nv"&gt;item&lt;/span&gt; &lt;span class="cp"&gt;}}&lt;/span&gt;&lt;span class="x"&gt; install_recommends=no update_cache=yes state=present&lt;/span&gt;
&lt;span class="x"&gt;        with_items:&lt;/span&gt;
&lt;span class="x"&gt;          - tomcat7&lt;/span&gt;
&lt;span class="x"&gt;          - tomcat7-admin&lt;/span&gt;
&lt;span class="x"&gt;        register: tomcat_installed&lt;/span&gt;

&lt;span class="x"&gt;      - name: Temporarily stop tomcat7&lt;/span&gt;
&lt;span class="x"&gt;        service: name=tomcat7 state=stopped&lt;/span&gt;
&lt;span class="x"&gt;        when: tomcat_installed|changed&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;As you can see from the snippet, I've not used a handler. Yes that's right, inorder to achieve the effect of an 'immediate' handler, I moved the task that stops tomcat7 service from the handler section to the tasks section.&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;Though I'm sure there are better solutions out there, I think the concept behind my quick fix can be useful in tackling other ansible-related issues.&lt;/p&gt;</summary><category term="linux"></category><category term="ansible"></category><category term="tomcat"></category></entry><entry><title>Maps and custom error pages in nginx</title><link href="https://nairobilug.or.ke/2014/12/maps-and-custom-error-pages-nginx.html" rel="alternate"></link><updated>2014-12-09T17:00:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2014-12-09:2014/12/maps-and-custom-error-pages-nginx.html</id><summary type="html">&lt;p&gt;During a recent web application upgrade I had to limit access to the the web servers; I wanted the administrators and myself to be able to access the site, but for everyone else to see an "&lt;em&gt;Under Construction&lt;/em&gt;" page. My initial plan was to test if the &lt;code&gt;$remote_addr&lt;/code&gt; was one of the allowed IPs, and then redirect those clients to a maintenance page, but I couldn't figure out how to test more than one IP address (seriously)!&lt;/p&gt;
&lt;p&gt;I eventually stumbled upon the &lt;a href="http://nginx.org/en/docs/http/ngx_http_map_module.html"&gt;nginx map module&lt;/a&gt; which, combined with a custom error page, ended up being an elegant, fun solution to this problem.&lt;/p&gt;
&lt;h3&gt;Elegant maps&lt;/h3&gt;
&lt;p&gt;Here is a snippet from &lt;em&gt;/etc/nginx/conf.d/default.conf&lt;/em&gt; which shows the important bits:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nt"&gt;server&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
&lt;span class="o"&gt;...&lt;/span&gt;

    &lt;span class="n"&gt;location&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;
        &lt;span class="n"&gt;if&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="err"&gt;$&lt;/span&gt;&lt;span class="n"&gt;denied&lt;/span&gt; &lt;span class="o"&gt;!=&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="err"&gt;{&lt;/span&gt;
            &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="n"&gt;HTTP&lt;/span&gt; &lt;span class="m"&gt;503&lt;/span&gt;&lt;span class="o"&gt;:&lt;/span&gt; &lt;span class="n"&gt;service&lt;/span&gt; &lt;span class="n"&gt;unavailable&lt;/span&gt;
            &lt;span class="n"&gt;return&lt;/span&gt; &lt;span class="m"&gt;503&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
         &lt;span class="p"&gt;}&lt;/span&gt;

         &lt;span class="err"&gt;#&lt;/span&gt; &lt;span class="nt"&gt;Send&lt;/span&gt; &lt;span class="nt"&gt;requests&lt;/span&gt; &lt;span class="nt"&gt;to&lt;/span&gt; &lt;span class="nt"&gt;Tomcat&lt;/span&gt;
         &lt;span class="nt"&gt;proxy_pass&lt;/span&gt; &lt;span class="nt"&gt;http&lt;/span&gt;&lt;span class="o"&gt;://&lt;/span&gt;&lt;span class="nt"&gt;127&lt;/span&gt;&lt;span class="nc"&gt;.0.0.1&lt;/span&gt;&lt;span class="nd"&gt;:8443&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="err"&gt;}&lt;/span&gt;

    &lt;span class="nt"&gt;error_page&lt;/span&gt; &lt;span class="nt"&gt;503&lt;/span&gt; &lt;span class="k"&gt;@maintenance&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;

    &lt;span class="nt"&gt;location&lt;/span&gt; &lt;span class="k"&gt;@maintenance&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
        &lt;span class="nt"&gt;root&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;tmp&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
        &lt;span class="nt"&gt;rewrite&lt;/span&gt; &lt;span class="o"&gt;^(.*)$&lt;/span&gt; &lt;span class="o"&gt;/&lt;/span&gt;&lt;span class="nt"&gt;maintenance&lt;/span&gt;&lt;span class="nc"&gt;.html&lt;/span&gt; &lt;span class="nt"&gt;break&lt;/span&gt;&lt;span class="o"&gt;;&lt;/span&gt;
    &lt;span class="p"&gt;}&lt;/span&gt;
&lt;span class="err"&gt;}&lt;/span&gt;

&lt;span class="nt"&gt;map&lt;/span&gt; &lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="nt"&gt;remote_addr&lt;/span&gt; &lt;span class="o"&gt;$&lt;/span&gt;&lt;span class="nt"&gt;denied&lt;/span&gt; &lt;span class="p"&gt;{&lt;/span&gt;
    &lt;span class="k"&gt;default&lt;/span&gt; &lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="m"&gt;18&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="m"&gt;216&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="m"&gt;110&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
    &lt;span class="m"&gt;192&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="m"&gt;64&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="m"&gt;147&lt;/span&gt;&lt;span class="o"&gt;.&lt;/span&gt;&lt;span class="m"&gt;150&lt;/span&gt; &lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;;&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;By default all IP addresses are denied (ie, &lt;code&gt;$denied=1&lt;/code&gt;), but depending on the client's IP address, the &lt;code&gt;$denied&lt;/code&gt; variable can be set to 0. In the root location block I essentially test if the IP address is denied and conditionally return an HTTP 503 (&lt;em&gt;Service Unavailable&lt;/em&gt;), which is handled by a custom &lt;code&gt;error_page&lt;/code&gt; handler with a named location block. So cool!&lt;/p&gt;
&lt;h3&gt;In retrospect&lt;/h3&gt;
&lt;p&gt;In retrospect I probably could have used a regex in the &lt;code&gt;$remote_addr&lt;/code&gt; test, but maps are really a more flexible, efficient, and "nginx" way of accomplishing this. On that note, I'm using nginx more and more lately and, in addition to being fast as hell and having better TLS support, it's just more fun to use than Apache. ;)&lt;/p&gt;
&lt;p&gt;Furthermore, to deploy this I wrote an Ansible playbook which included a list of allowed IPs and reconfigured the nginx vhost by using a Jinja2 template which iterated over the IPs to create the map block above. Very cool, and very easy to reverse when the maintenance was over!&lt;/p&gt;
&lt;p&gt;This was originally &lt;a href="https://mjanja.ch/2014/12/maps-and-custom-error-pages-in-nginx/"&gt;posted on&lt;/a&gt; on my personal blog; re-posted here for posterity.&lt;/p&gt;</summary><category term="linux"></category><category term="nginx"></category></entry><entry><title>Image compression like Compressor.io, but with open-source tools</title><link href="https://nairobilug.or.ke/2014/10/image-compression-open-source.html" rel="alternate"></link><updated>2014-10-23T10:40:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2014-10-23:2014/10/image-compression-open-source.html</id><summary type="html">&lt;p&gt;When I first tried &lt;a href="https://compressor.io"&gt;Compressor.io&lt;/a&gt; I was shocked; how can they reduce an image's file size by hundreds of kilobytes or more without downscaling the image and no noticeable loss in quality?  Although it's a cool, free tool, it bothered me that, because I didn't know how to do this myself, I was depending on a "cloud" service to do it for me.  Surely that web service is just a snazzy front end for the free, libre, open-source tools we all know and love?&lt;/p&gt;
&lt;p&gt;I was pretty sure the answers lay in GraphicsMagick / ImageMagick, but with which options?  What was the magic invocation that would produce the same result?&lt;/p&gt;
&lt;p&gt;&lt;abbr title="Too long; didn't read"&gt;TL;DR&lt;/abbr&gt;: Strip EXIF data, interlace, convert to 80% quality, and scale to ~50% of original image dimensions.&lt;/p&gt;
&lt;h3&gt;It's easy!&lt;/h3&gt;
&lt;p&gt;After a bit of Google-fu I learned that this is easier than I had originally thought.  For example, take this picture of me eating a piece of halloumi cheese:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Alan eating halloumi" src="/images/alan-halloumi.jpg" title="Alan eating halloumi" /&gt;&lt;/p&gt;
&lt;p&gt;Straight from the fancy DSLR camera the image is &lt;em&gt;3.6 megabytes&lt;/em&gt; — much too large to share practically on the web.  Amazingly, after uploading to Compressor.io the image is reduced to &lt;em&gt;1.6 megabytes&lt;/em&gt;.  That's an impressive feat considering the image wasn't downscaled and is visually indistinguishable from the original!&lt;/p&gt;
&lt;p&gt;As it turns out, it's actually pretty easy to achieve this level of savings:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;jpegtran -copy none -progressive -outfile DSC_0685-trimmed.JPG DSC_0685.JPG
&lt;span class="nv"&gt;$ &lt;/span&gt;gm mogrify DSC_0685-trimmed.JPG -quality 80
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The result is actually &lt;em&gt;better&lt;/em&gt; than Compressor.io:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;ls -lht DSC_0685*
-rw-r--r-- &lt;span class="m"&gt;1&lt;/span&gt; aorth staff 1.4M Oct &lt;span class="m"&gt;14&lt;/span&gt; 21:52 DSC_0685-trimmed.JPG
-rw-r--r-- &lt;span class="m"&gt;1&lt;/span&gt; aorth staff 1.6M Oct &lt;span class="m"&gt;14&lt;/span&gt; 20:47 DSC_0685-compressor.jpg
-rw-r--r-- &lt;span class="m"&gt;1&lt;/span&gt; aorth staff 3.6M Jun &lt;span class="m"&gt;28&lt;/span&gt; 11:21 DSC_0685.JPG
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;The first operation — &lt;code&gt;jpegtran&lt;/code&gt; — is "lossless".  That is, it doesn't change the image data itself, instead optimizing the image's compression algorithm and stripping the EXIF data, and converts to &lt;em&gt;&lt;a href="http://www.bookofspeed.com/chapter5.html"&gt;progressive JPEGs&lt;/a&gt;&lt;/em&gt;.  EXIF data, like GPS coordinates, exposure length, ISO, etc are useful to the photographer or image manipulation software, but not essential when uploading to the web.&lt;/p&gt;
&lt;p&gt;The second operation — GraphicsMagick — is "lossy" because it reduces the image to 80% quality.  GraphicsMagick's &lt;code&gt;mogrify&lt;/code&gt; command is very similar to the &lt;code&gt;convert&lt;/code&gt; command, but it &lt;em&gt;edits files in place&lt;/em&gt; (so be careful!).&lt;/p&gt;
&lt;h3&gt;Extra points&lt;/h3&gt;
&lt;p&gt;Even though the file size has reduced by an amazing 60%, the image is actually still pretty massive — both in terms of file size as well as dimensions.  At &lt;em&gt;4608x3072 pixels&lt;/em&gt; (14MP), the image is still too large for the average computer, tablet, or phone to consume practically.  Keep in mind that, in 2014, most high-end smart phones have a resolution of "only" &lt;em&gt;1920x1080 pixels&lt;/em&gt;!&lt;/p&gt;
&lt;p&gt;Given that high-end smart phones literally can't even fit more than 50% of this image on the screen, it's safe to assume that we can scale down the dimensions by a factor of at least 50% without sacrificing too much... I'll sympathize with the bandwidth deprived and go for 40%:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nv"&gt;$ &lt;/span&gt;gm convert DSC_0685-trimmed.JPG -resize 40% -quality &lt;span class="m"&gt;80&lt;/span&gt; -interlace Line DSC_0685-trimmed-scaled.JPG
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After this the file is a mere &lt;em&gt;357 kilobytes&lt;/em&gt;, yet still nearly indistinguishable from the original!&lt;/p&gt;
&lt;p&gt;This command is a bit of a mystery to me, though.  For some reason, in this particular invocation, &lt;code&gt;convert&lt;/code&gt; yields a smaller file size than &lt;code&gt;mogrify&lt;/code&gt;, even with the same exact options.  Also, even though we converted to progressive with &lt;code&gt;jpegtran&lt;/code&gt; earlier, doing it again here seems to have a substantial effect on the resulting file size (12k in this example).  Oh well, I suppose you can't understand everything all at once. ;)&lt;/p&gt;
&lt;h3&gt;Great success!&lt;/h3&gt;
&lt;p&gt;So there you have it, now you get that Compressor.io-like effect from the safety of your own home, with free, libre, open-source software!&lt;/p&gt;
&lt;p&gt;This was &lt;a href="https://mjanja.ch/2014/10/image-compression-like-compressor-io-but-with-open-source-tools/"&gt;originally posted&lt;/a&gt; on my personal blog; re-posted here for posterity.&lt;/p&gt;</summary><category term="linux"></category><category term="images"></category><category term="photography"></category></entry><entry><title>Update hosts via Ansible to mitigate bash "Shellshock" vulnerability</title><link href="https://nairobilug.or.ke/2014/09/ansible-shellshock.html" rel="alternate"></link><updated>2014-09-29T10:40:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2014-09-29:2014/09/ansible-shellshock.html</id><summary type="html">&lt;p&gt;On September 24, 2014 someone &lt;a href="http://seclists.org/oss-sec/2014/q3/649" title="CVE-2014-6271: remote code execution through bash"&gt;posted&lt;/a&gt; on the oss-sec mailing list about a &lt;code&gt;bash&lt;/code&gt; vulnerability that likely affects several decades of &lt;code&gt;bash&lt;/code&gt;  versions (something like &lt;code&gt;1.14&lt;/code&gt; - &lt;code&gt;4.3&lt;/code&gt;!).  The vulnerability — aptly named "Shellshock" — can lead to remote code execution on un-patched hosts, for example &lt;a href="http://www.nimbo.com/blog/shellshock-heartbleed-2-0"&gt;web servers parsing HTTP environment variables via CGI GET requests&lt;/a&gt;, &lt;a href="https://community.qualys.com/blogs/laws-of-vulnerabilities/2014/09/24/bash-shellshock-vulnerability" title="BASH Shellshock vulnerability - Update3"&gt;sshd configurations using &lt;code&gt;ForceCommand&lt;/code&gt;&lt;/a&gt;, &lt;a href="https://www.trustedsec.com/september-2014/shellshock-dhcp-rce-proof-concept/" title="Shellshock DHCP RCE PoC"&gt;DHCP clients&lt;/a&gt;, etc.&lt;/p&gt;
&lt;p&gt;Anyways, I'll leave the infosec community to &lt;a href="https://www.dfranke.us/posts/2014-09-27-shell-shock-exploitation-vectors.html" title="Shell Shock Exploitation Vectors"&gt;expound on attack vectors&lt;/a&gt;.  The point of this post is really to illustrate that you should be using an infrastructure orchestration tool like &lt;a href="http://www.ansible.com/home" title="Ansible homepage"&gt;Ansible&lt;/a&gt; to manage your servers.&lt;/p&gt;
&lt;h3&gt;Painless patching with Ansible&lt;/h3&gt;
&lt;p&gt;Patching your systems is painlessly easy if you manage your server infrastructure with something like Ansible.  Using a one-off command you can easily update all "web" servers, for example:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ansible web -m apt -a &lt;span class="s2"&gt;&amp;quot;name=bash state=latest update_cache=yes&amp;quot;&lt;/span&gt; -K -s
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;That's great, but what if you have both Ubuntu and CentOS hosts in the "web" group?  CentOS doesn't use &lt;code&gt;apt&lt;/code&gt; for package management, so this has effectively only updated hosts running Debian-family GNU/Linux distros.&lt;/p&gt;
&lt;h3&gt;Playbooks: the power of Ansible&lt;/h3&gt;
&lt;p&gt;When you have more than a handful of servers, the combinations of DNS names, IP addresses, roles, and distros becomes overwhelming.  With Ansible you define your inventory of hosts, allocate them into groups, and then write "playbooks" to mold your servers into functional roles, ie web, database, compute, proxy, etc servers; the &lt;a href="https://xkcd.com/910/" title="XKCD coming about naming servers"&gt;personal relationship&lt;/a&gt; between sysadmin and server is gone.&lt;/p&gt;
&lt;p&gt;Here's a simple playbook I wrote which takes into account the different OS families in our infrastructure and updates the &lt;code&gt;bash&lt;/code&gt; package on each host.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;shellshock.yml&lt;/em&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="nn"&gt;---&lt;/span&gt;
&lt;span class="c1"&gt;# To update hosts for &amp;quot;Shellshock&amp;quot; bash vulnerability&lt;/span&gt;
&lt;span class="c1"&gt;# See: https://en.wikipedia.org/wiki/Shellshock_(software_bug)&lt;/span&gt;

&lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;hosts&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;all&lt;/span&gt;
  &lt;span class="l-Scalar-Plain"&gt;sudo&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;yes&lt;/span&gt;
  &lt;span class="l-Scalar-Plain"&gt;tasks&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt;
    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;name&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;Update on Debian-based distros&lt;/span&gt;
      &lt;span class="l-Scalar-Plain"&gt;apt&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;name=bash state=latest update_cache=yes&lt;/span&gt;
      &lt;span class="l-Scalar-Plain"&gt;when&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;ansible_os_family == &amp;quot;Debian&amp;quot;&lt;/span&gt;

    &lt;span class="p-Indicator"&gt;-&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;name&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;Update on RedHat-based distros&lt;/span&gt;
      &lt;span class="l-Scalar-Plain"&gt;yum&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;name=bash state=latest&lt;/span&gt;
      &lt;span class="l-Scalar-Plain"&gt;when&lt;/span&gt;&lt;span class="p-Indicator"&gt;:&lt;/span&gt; &lt;span class="l-Scalar-Plain"&gt;ansible_os_family == &amp;quot;RedHat&amp;quot;&lt;/span&gt;

&lt;span class="c1"&gt;# vim: set sw=2 ts=2:&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;And then run the playbook with:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; ansible-playbook shellshock.yml -K -s
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;In our case we patched twenty-five CentOS 6.x, Debian 6, Debian 7, Ubuntu 12.04, and Ubuntu 14.04 hosts living locally, in Amazon EC2, and in Linode.  With one command.  In less than five minutes!&lt;/p&gt;
&lt;h3&gt;Stay vigilant!&lt;/h3&gt;
&lt;p&gt;Vendors started pushing patched versions of &lt;code&gt;bash&lt;/code&gt; on September 26th, two days after the initial disclosure.  Two days after those patched versions were released there were &lt;a href="http://lcamtuf.blogspot.com/2014/09/bash-bug-apply-unofficial-patch-now.html" title="Bash bug: apply Florian"&gt;new variations of this bug discovered&lt;/a&gt;, and new packages issued (and we patched our systems again!).&lt;/p&gt;
&lt;p&gt;As of now, five days after initial disclosure, there exist five &lt;abbr title="Common Vulnerabilities and Exposures"&gt;CVE&lt;/abbr&gt; identifiers for this bug!  So keep an eye on social media (&lt;a href="https://twitter.com/search?q=%23shellshock" title="#shellshock on Twitter"&gt;#shellshock&lt;/a&gt;?), &lt;a href="https://news.ycombinator.com/" title="Hacker News"&gt;Hacker News&lt;/a&gt;, and &lt;a href="https://shellshocker.net/" title="Shellshock monitoring"&gt;sites monitoring this bug&lt;/a&gt;, because more new vectors may emerge!&lt;/p&gt;
&lt;p&gt;This was &lt;a href="https://mjanja.ch/2014/09/update-hosts-via-ansible-to-mitigate-bash-shellshock-vulnerability/"&gt;originally posted&lt;/a&gt; on my personal blog; re-posted here for posterity.&lt;/p&gt;</summary><category term="linux"></category><category term="ansible"></category><category term="bash"></category><category term="security"></category></entry><entry><title>Exploring anti-DOS tools for Apache httpd</title><link href="https://nairobilug.or.ke/2014/09/exploring-anti-DOS-tools-for-Apache-httpd.html" rel="alternate"></link><updated>2014-09-13T18:28:00+03:00</updated><author><name>John Troon</name></author><id>tag:nairobilug.or.ke,2014-09-13:2014/09/exploring-anti-DOS-tools-for-Apache-httpd.html</id><summary type="html">&lt;p&gt;Slowloris is among the well known "Denial Of Service" (or DOS) &lt;a href="http://resources.infosecinstitute.com/dos-attacks-free-dos-attacking-tools/"&gt;tool&lt;/a&gt; used by both experienced attackers and script kiddies. This evening, I've been testing &lt;em&gt;mod_evasion&lt;/em&gt; and &lt;em&gt;mod_antiloris&lt;/em&gt; on Apache httpd /2.2.15 (Oracle Linux 6.5 using Redhat built Kernel).&lt;/p&gt;
&lt;h2&gt;First Setup:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Server: 192.168.43.221 (running Apache httpd with &lt;em&gt;mod_evasion&lt;/em&gt; loaded)&lt;/li&gt;
&lt;li&gt;Attacking Machine: 192.168.43.39 (Slowloris "DOSing" the server)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Apache httpd error logs&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Error from bad requests" src="/images/badheader.png" title="Apache error logs" /&gt;&lt;/p&gt;
&lt;p&gt;The loaded module (&lt;em&gt;mod_evasion&lt;/em&gt;), can't save Apache httpd from the DOS attack, even loading the site from a browser is somehow impossible.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Apache DOSed" src="/images/apachedown.png" title="Can't access via Browser" /&gt;&lt;/p&gt;
&lt;p&gt;But this module can prevent a brute-force attack (&lt;em&gt;e.g. an automated script to guess a password field in a web-form&lt;/em&gt;) in a web server (running Apache httpd).&lt;/p&gt;
&lt;p&gt;&lt;img alt="mod_evasion can prevent Brute-force.." src="/images/bruteforce.png" title="mod_evasion can prevent Brute-force attack" /&gt;&lt;/p&gt;
&lt;p&gt;Just to make an interesting comparison, I replaced Apache httpd with Nginx on the same Server (192.168.43.221) and &lt;strong&gt;ta! da!..&lt;/strong&gt;
&lt;img alt="Nginx is not DOSed by Slowloris" src="/images/nginxup.png" title="Nginx is not DOSed by Slowloris" /&gt; Nginx gracefully made it by ignoring the request from  Slowloris. But I noticed a brute-force attack is possible while using Nginx default settings! &lt;strong&gt;Nginx access logs&lt;/strong&gt;
&lt;img alt="Nginx Brute-forced" src="/images/bfnginx.png" title="Nginx can be Brute-forced" /&gt;&lt;/p&gt;
&lt;h2&gt;Second Setup:&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Server: 192.168.43.221 (running Apache httpd with mod_antiloris loaded)&lt;/li&gt;
&lt;li&gt;Attacking Machine: 192.168.43.39 (Sowloris "DOSing" the server)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;em&gt;mod_antiloris&lt;/em&gt; played it nice by monitoring the requests coming from the client and rejected extra connections. Accessing the web services from the browser was not interfered.&lt;/p&gt;
&lt;p&gt;&lt;img alt="mod_antiloris logs" src="/images/antiloris.png" title="mod_antiloris logs" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;mod_evasion&lt;/em&gt; is cool but can't save Apache httpd from Slowloris. On the other hand, &lt;em&gt;mod_antiloris&lt;/em&gt; worked fine and denied Slowloris a chance to mess up with the Apache httpd server.&lt;/p&gt;
&lt;h2&gt;Explanation:&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Putting the Lens on the Logs...&lt;/strong&gt; (Apache httpd access log)&lt;/p&gt;
&lt;p&gt;&lt;img alt="Apache-httpd access log" src="/images/accesslog.png" title="Apache httpd access logs" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Why did mod_antiloris pass the test and mod_evasion fail?..&lt;/em&gt; &lt;em&gt;Why did Slowloris work on Apache httpd and not on Nginx?&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Apache httpd waits for a &lt;strong&gt;complete HTTP request header&lt;/strong&gt; to be received, this makes it good to serve web-content even in slow connections. So, by default, the timeout value is 300 seconds and it's reset each time the client sends more packets. Slowloris takes advantage by sending incomplete HTTP request headers and maintains the connection by sending more incomplete request headers resetting the time-out counter.&lt;/p&gt;
&lt;p&gt;Slowloris is written in Perl, it simply plays around with &lt;strong&gt;CR (Carriage Return)&lt;/strong&gt; and &lt;strong&gt;LF (Line Feed)&lt;/strong&gt; at the end of every incomplete HTTP request header. A blank line after the request header is used to represent the completion of the header in HTTP. Since the request is incomplete and the timeout is 300 seconds, Apache httpd will keep the connection alive waiting for the remaining data, while Slowloris keeps on sending the incomplete HTTP requests resetting the timeout counter.&lt;/p&gt;
&lt;p&gt;As a result, all available connections will be sucked up by Slowloris and cause a Denial of Service. mod_antiloris helped Apache httpd beat Slowloris but you can also use IPtables by setting a connection limit or putting Apache httpd behind Varnish. Another solution I've not tested is using a Hardware Load Balancer that only accepts full HTTP connections.&lt;/p&gt;
&lt;p&gt;Nginx uses a much more event-driven (asynchronous) architecture that can be scaled, instead of the "Maximum Connections" as in Apache httpd. So, in a nutshell, Nginx ignores the requests from Slowloris and processes other "full" connections.&lt;/p&gt;
&lt;p&gt;This is not to claim that Nginx is bullet proof by default, tools like &lt;a href="https://github.com/valyala/goloris"&gt;golris&lt;/a&gt; can mess with your Nginx server (when running with default settings), though you can always protect this from happening by using Nginx "Http limit connection" module / IPtables / deny POST requests or patch Nginx, so it drops connection if the client sends POST body at a very slow rate.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;But I'll always go with Nginx whenever possible!&lt;/strong&gt;&lt;/p&gt;
&lt;h3&gt;Conclusion&lt;/h3&gt;
&lt;p&gt;I think Apache httpd should find a way of prioritizing clients sending full HTTP requests to minimize DOS attacks of the (above) described nature...&lt;/p&gt;
&lt;p&gt;Ciao! &lt;/p&gt;</summary><category term="linux"></category><category term="security"></category><category term="httpd"></category><category term="nginx"></category></entry><entry><title>The "SCTP" protocol</title><link href="https://nairobilug.or.ke/2014/09/SCTP-protocol.html" rel="alternate"></link><updated>2014-09-04T18:37:00+03:00</updated><author><name>John Troon</name></author><id>tag:nairobilug.or.ke,2014-09-04:2014/09/SCTP-protocol.html</id><summary type="html">&lt;p&gt;TCP and UDP protocols have been in around for approximately 20+ years now. Even though they have helped in building nice Internet applications since inception, things are changing in the techie world and they will always change. TCP being a connection state protocol while UDP a connectionless state protocol, there have been attempts to build a general purpose protocol above the IP layer, SCTP so far is the only one endorsed by  the IETF.&lt;/p&gt;
&lt;p&gt;SCTP combines concepts from TCP and UDP for even better control over the transport of packets (with additional API calls for SCTP). TCP applications can be ported to SCTP.&lt;/p&gt;
&lt;h2&gt;Some Cool Features:&lt;/h2&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;More Support for multi-homed devices:&lt;/strong&gt; 
Laptops these days can come with more than one in-built Ethernet cards, wireless cards, wiMAX cards and Bluetooth... Hence, a minimal laptop can at-least have 3 distinct IP network interfaces. SCTP support selective choosing of interfaces with ability to add and drop interfaces dynamically. You can unplug your machine from an Ethernet network, and an Internet application immediately pick up with existing  wifi connection etc.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Whoo! Multi-streaming:&lt;/strong&gt; 
An application doesn't need multiple sockets rather a single socket that can be used for multiple streams to a connected host! Let's say the X Window System is connecting on multiple ports, with SCTP, these could all be separate streams on a single association. &lt;em&gt;Fast-Browsing!&lt;/em&gt;, HTML docs containing referenced image files or other media files, they will load faster with SCTP compared in TCP. HTTP use separate TCP connection per downloaded URL, even with HTTP 1.1 "persistent connections" it's still expensive. With SCTP, the separate media files could be downloaded concurrently in separate streams on a single association.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;No “out of band”... :&lt;/strong&gt; 
SCTP has no “out of band” messages, but a large number of events can be interleaved onto a single association, so that an application can monitor the state of the association (e.g. when the other end adds another interface to the association).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Greater socket range:&lt;/strong&gt; 
The range of socket options is greater than TCP or UDP. These also can be used to control individual associations or individual streams
 within a single association. For example, messages on one stream can be given a longer time-to-live than messages on other streams, increasing the likelihood of their delivery.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Do more with single socket:&lt;/strong&gt;
A single socket can support multiple associations, that is, a computer can use a single socket to talk to more than one computer. This is not multicast, but it could be useful in peer-to-peer situations&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Still message-oriented.. :&lt;/strong&gt; 
TCP is a byte-oriented protocol, and UDP is message-oriented. The majority of applications are message-oriented, and applications using TCP have to jump through hoops, such as sending the message length as a first parameter. SCTP is message-oriented, so such tricks are not so necessary.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;blockquote&gt;
&lt;p&gt;It is no longer necessary to open up multiple sockets; instead, a single socket can be used for multiple streams to a connected host. SCTP tries to provide a more reliable and robust protocol than either TCP or UDP. Btw, SCTP is not in any Microsoft release, another reason to love Linux? :)&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Resources&lt;/h2&gt;
&lt;p&gt;&lt;a href="http://www.sctp.de"&gt;The Main  Site for SCTP &lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="https://lists.sourceforge.net/lists/listinfo/lksctp-developers"&gt;The Linux Kernel Project Home Page&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://en.wikipedia.org/wiki/Stream_Control_Transmission_Protocol"&gt;Stream Control Transmission Protocol(SCTP)&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;a href="http://www.slideshare.net/PeterREgli/overview-of-sctp-transport-protocol"&gt;Overview of SCTP (Stream Control Transmission Protocol)&lt;/a&gt;&lt;/p&gt;</summary><category term="Tech"></category><category term="Linux"></category><category term="programming"></category></entry><entry><title>Meetup Summary (August, 2014)</title><link href="https://nairobilug.or.ke/2014/08/meetup-august-2014.html" rel="alternate"></link><updated>2014-08-02T16:00:00+03:00</updated><author><name>Jason Rogena</name></author><id>tag:nairobilug.or.ke,2014-08-02:2014/08/meetup-august-2014.html</id><summary type="html">&lt;p&gt;12 guys showed up, most well after 4PM. Congrats to Muya for being the only one to make it on time. The meetup was just as exciting, at least for me, as most of previous meetups.&lt;/p&gt;
&lt;h3&gt;Highlights:&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;There was a suggestion that the LUG should build a portable 'blood-glucose measuring device that plugs into a phone's audio jack' (I'm sure there's a shorter name for that) as a collaborative project, given the talent in the LUG.&lt;/li&gt;
&lt;li&gt;There was some discussion on WebRTC and its apparent bright future. Somebody even created a group for the LUG on [talky] (https://talky.io/nairobilug). No nudity please ;).&lt;/li&gt;
&lt;li&gt;No females were present in the meetup. We seriously need to get nerdy girls to come to the meetups. ~~I think~~ I'm certain there are cool girls out there... somewhere.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Leave comments down below and if I've left anything, feel free to make a pull request.&lt;/p&gt;
&lt;h3&gt;Pictures from Google+&lt;/h3&gt;
&lt;p&gt;Picture courtesy of Mungai&lt;/p&gt;
&lt;p&gt;&lt;img alt="Drinks" src="/images/meetup-august-2014.jpg" title="Nairobi GNU/Linux Users Group members" /&gt;&lt;/p&gt;
&lt;h3&gt;September Meetup&lt;/h3&gt;
&lt;p&gt;The Nairobi LUG meets every first Saturday of the month. The next meetup will therefore be on the 7th of September. Can't wait :)&lt;/p&gt;</summary><category term="KFC"></category><category term="meetup"></category></entry><entry><title>Using swiftclient for object storage on OpenStack</title><link href="https://nairobilug.or.ke/2014/07/swiftclient-openstack.html" rel="alternate"></link><updated>2014-07-29T19:40:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2014-07-29:2014/07/swiftclient-openstack.html</id><summary type="html">&lt;p&gt;I wanted to play with my new account on East African OpenStack provider &lt;a href="http://kili.io/"&gt;Kili.io&lt;/a&gt;, specifically to use the OpenStack Swift object storage to do periodic backups from my desktop.  I'd used tools like &lt;a href="http://s3tools.org/s3cmd"&gt;s3cmd&lt;/a&gt; to do backups to Amazon S3 object storage, but it doesn't seem to work with OpenStack's &lt;a href="http://docs.openstack.org/developer/swift/"&gt;Swift&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="https://www.swiftstack.com/docs/integration/python-swiftclient.html"&gt;python-swiftclient&lt;/a&gt; seems to be the answer. These are my notes from getting it set up to backup some data from my desktop to my shiny new OpenStack provider.&lt;/p&gt;
&lt;h3&gt;See also&lt;/h3&gt;
&lt;p&gt;Related links and documentation:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://docs.openstack.org/grizzly/openstack-object-storage/admin/content/swift-cli-basics.html"&gt;Swift CLI Basic&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://docs.openstack.org/user-guide/content/managing-openstack-object-storage-with-swift-cli.html"&gt;Manage objects and containers&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Download RC file&lt;/h2&gt;
&lt;p&gt;This is actually the trickiest part of this whole exercise (you're welcome!).  For an outsider, the OpenStack API jargon is a bit overwhelming.  Luckily, I found that OpenStack provides a shell init script which will set all the shell environment variables you need to get started with &lt;code&gt;swiftclient&lt;/code&gt; (and presumably other OpenStack tools).&lt;/p&gt;
&lt;p&gt;In the dashboard, navigate to &lt;code&gt;Project -&amp;gt; Compute -&amp;gt; Access &amp;amp; Security -&amp;gt; Download OpenStack RC File&lt;/code&gt;.  We'll need this later.&lt;/p&gt;
&lt;h2&gt;Create and prepare virtualenv&lt;/h2&gt;
&lt;p&gt;There's no &lt;code&gt;swiftclient&lt;/code&gt; package in my GNU/Linux distribution, so I decided to just install it into a virtual environment straight from pypi/pip.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; mkvirtualenv -p &lt;span class="sb"&gt;`&lt;/span&gt;which python2&lt;span class="sb"&gt;`&lt;/span&gt; swift
&lt;span class="gp"&gt;$&lt;/span&gt; pip install python-swiftclient python-keystoneclient
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Setup the environment&lt;/h2&gt;
&lt;p&gt;Source the environment RC script you downloaded from the OpenStack dashboard:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; . ~/Downloads/aorth-openrc.sh
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;It will prompt you for your OpenStack dashboard password.&lt;/p&gt;
&lt;h2&gt;Test&lt;/h2&gt;
&lt;p&gt;Check if the settings are correct:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; swift stat
&lt;span class="go"&gt;       Account: AUTH_8b0c9cff5d094829b0cf7606a0390c1a&lt;/span&gt;
&lt;span class="go"&gt;    Containers: 0&lt;/span&gt;
&lt;span class="go"&gt;       Objects: 0&lt;/span&gt;
&lt;span class="go"&gt;         Bytes: 0&lt;/span&gt;
&lt;span class="go"&gt; Accept-Ranges: bytes&lt;/span&gt;
&lt;span class="go"&gt;        Server: nginx/1.4.7&lt;/span&gt;
&lt;span class="go"&gt;    Connection: keep-alive&lt;/span&gt;
&lt;span class="go"&gt;   X-Timestamp: 1406586841.02692&lt;/span&gt;
&lt;span class="go"&gt;    X-Trans-Id: tx5d47eff065074335a3a9f-0053d7c93e&lt;/span&gt;
&lt;span class="go"&gt;  Content-Type: text/plain; charset=utf-8&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;This means the API key and all other settings are ok, and authentication was successful; you're now ready to use OpenStack CLI tools.&lt;/p&gt;
&lt;h2&gt;Create a container&lt;/h2&gt;
&lt;p&gt;You could create a container in the OpenStack dashboard (&lt;code&gt;Object Store -&amp;gt; Containers -&amp;gt; Create Container&lt;/code&gt;), but it's much nicer to be able to do this from the commandline using the API.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; swift post Documents
&lt;span class="gp"&gt;$&lt;/span&gt; swift list
&lt;span class="go"&gt;Documents&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;h2&gt;Upload files&lt;/h2&gt;
&lt;p&gt;My use case is to backup Documents from my desktop.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nb"&gt;cd&lt;/span&gt; ~/Documents
&lt;span class="gp"&gt;$&lt;/span&gt; swift upload Documents *
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; I &lt;code&gt;cd&lt;/code&gt; into the directory I want to upload first, because I found that if I wasn't &lt;em&gt;inside&lt;/em&gt; it, I would end up with another layer of hierarchy in my container itself, ie &lt;code&gt;Documents/Documents&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;Check the status of the container:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; swift stat Documents
&lt;span class="go"&gt;       Account: AUTH_9b0a8aff5d584828b5af7656c0385a1c&lt;/span&gt;
&lt;span class="go"&gt;     Container: Documents&lt;/span&gt;
&lt;span class="go"&gt;       Objects: 2691&lt;/span&gt;
&lt;span class="go"&gt;         Bytes: 262663872&lt;/span&gt;
&lt;span class="go"&gt;      Read ACL:&lt;/span&gt;
&lt;span class="go"&gt;     Write ACL:&lt;/span&gt;
&lt;span class="go"&gt;       Sync To:&lt;/span&gt;
&lt;span class="go"&gt;      Sync Key:&lt;/span&gt;
&lt;span class="go"&gt; Accept-Ranges: bytes&lt;/span&gt;
&lt;span class="go"&gt;        Server: nginx/1.4.7&lt;/span&gt;
&lt;span class="go"&gt;    Connection: keep-alive&lt;/span&gt;
&lt;span class="go"&gt;   X-Timestamp: 1406586841.13379&lt;/span&gt;
&lt;span class="go"&gt;    X-Trans-Id: txbf31671156c64147bd9ad-0053d767c9&lt;/span&gt;
&lt;span class="go"&gt;  Content-Type: text/plain; charset=utf-8&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Looks good!  ~250MB of data in my &lt;code&gt;Documents&lt;/code&gt; container now, which just about matches the size of the folder on my disk. &lt;/p&gt;
&lt;h2&gt;Bonus points&lt;/h2&gt;
&lt;p&gt;Bonus points and future research:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;If I want to call this from a cron job, how do I enter my password?&lt;/li&gt;
&lt;li&gt;How do I encrypt my backups?&lt;/li&gt;
&lt;li&gt;Use &lt;code&gt;--skip-identical&lt;/code&gt; to only sync new files&lt;/li&gt;
&lt;li&gt;What other interfaces are there to this storage, ie can I point a music player at this?&lt;/li&gt;
&lt;li&gt;Play with public/private read/write ACLs&lt;/li&gt;
&lt;/ul&gt;</summary><category term="linux"></category><category term="openstack"></category><category term="swift"></category></entry><entry><title>Parallelizing rsync</title><link href="https://nairobilug.or.ke/2014/07/parallelizing-rsync.html" rel="alternate"></link><updated>2014-07-11T16:40:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2014-07-11:2014/07/parallelizing-rsync.html</id><summary type="html">&lt;p&gt;Last week I had a massive hardware failure on one of the GlusterFS storage nodes in the &lt;a href="http://hpc.ilri.cgiar.org/"&gt;ILRI, Kenya Research Computing cluster&lt;/a&gt;; two drives failed simultaneously on the underlying RAID5. As RAID5 can only withstand one drive failure, the entire 31TB array was toast. FML.&lt;/p&gt;
&lt;p&gt;After replacing the failed disks, rebuilding the array, and formatting my bricks, I decided I would use &lt;code&gt;rsync&lt;/code&gt; to pre-seed my bricks from the good node before bringing &lt;code&gt;glusterd&lt;/code&gt; back up.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;tl;dr&lt;/em&gt;: &lt;code&gt;rsync&lt;/code&gt; is amazing, but it’s single threaded and struggles when you tell it to sync large directory hierarchies.  &lt;a href="#sync_bricks"&gt;Here's how you can speed it up&lt;/a&gt;.&lt;/p&gt;
&lt;h3&gt;rsync #fail&lt;/h3&gt;
&lt;p&gt;I figured syncing the brick hierarchy from the good node to the bad node was simple enough, so I stopped the &lt;code&gt;glusterd&lt;/code&gt; service on the bad node and invoked:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="gp"&gt;#&lt;/span&gt; rsync -aAXv --delete --exclude&lt;span class="o"&gt;=&lt;/span&gt;.glusterfs storage0:/path/to/bricks/homes/ storage1:/path/to/bricks/homes/
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;After a day or so I noticed I had only copied ~1.5TB (over 1 hop on a dedicated 10GbE switch!), and I realized something must be wrong.  I attached to the &lt;code&gt;rsync&lt;/code&gt; process with &lt;code&gt;strace -p&lt;/code&gt; and saw a bunch of system calls in one particular user’s directory. I dug deeper:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="gp"&gt;#&lt;/span&gt; find /path/to/bricks/homes/ukenyatta/maker/genN_datastore/ -type d &lt;span class="p"&gt;|&lt;/span&gt; wc -l
&lt;span class="go"&gt;1398640&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;So this one particular directory in one user's home contained over a million &lt;em&gt;other&lt;/em&gt; directories and $god knows how many files, and this command itself took several hours to finish!  To make matters worse, careful trial and error inspection of other user home directories revealed more massive directory structures as well.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;rsync is single threaded&lt;/li&gt;
&lt;li&gt;rsync generates a list of files to be synced before it starts the sync&lt;/li&gt;
&lt;li&gt;MAKER creates a ton of output files/directories&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;It's pretty clear (now) that a recursive &lt;code&gt;rsync&lt;/code&gt; on my huge directory hierarchy is out of the question!&lt;/p&gt;
&lt;h3&gt;rsync #win&lt;/h3&gt;
&lt;p&gt;I had a look around and saw lots of people complaining about &lt;code&gt;rsync&lt;/code&gt; being "slow" and others suggesting tips to speed it up.  One very promising strategy was described on &lt;a href="https://wiki.ncsa.illinois.edu/display/~wglick/Parallel+Rsync"&gt;this wiki&lt;/a&gt; and there's a great discussion in the comments.&lt;/p&gt;
&lt;p&gt;Basically, he describes a clever use of &lt;code&gt;find&lt;/code&gt; and &lt;code&gt;xargs&lt;/code&gt; to split up the problem set into smaller pieces that &lt;code&gt;rsync&lt;/code&gt; can process more quickly.&lt;/p&gt;
&lt;h3&gt;sync_brick.sh&lt;/h3&gt;
&lt;p&gt;So here's my adaptation of his script for the purpose of syncing failed GlusterFS bricks, &lt;code&gt;sync_brick.sh&lt;/code&gt;:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c"&gt;#!/bin/env bash&lt;/span&gt;
&lt;span class="c"&gt;# borrowed / adapted from: https://wiki.ncsa.illinois.edu/display/~wglick/Parallel+Rsync&lt;/span&gt;

&lt;span class="c"&gt;# RSYNC SETUP&lt;/span&gt;
&lt;span class="nv"&gt;RSYNC_PROG&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/usr/bin/rsync
&lt;span class="c"&gt;# note the important use of --relative to use relative paths so we don&amp;#39;t have to specify the exact path on dest&lt;/span&gt;
&lt;span class="nv"&gt;RSYNC_OPTS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;-aAXv --numeric-ids --progress --human-readable --delete --exclude=.glusterfs --relative&amp;quot;&lt;/span&gt;
&lt;span class="nb"&gt;export &lt;/span&gt;&lt;span class="nv"&gt;RSYNC_RSH&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;ssh -T -c arcfour -o Compression=no -x&amp;quot;&lt;/span&gt;

&lt;span class="c"&gt;# ENV SETUP&lt;/span&gt;
&lt;span class="nv"&gt;SRCDIR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/path/to/good/brick
&lt;span class="nv"&gt;DESTDIR&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;/path/to/bad/brick
&lt;span class="c"&gt;# Recommend to match # of CPUs&lt;/span&gt;
&lt;span class="nv"&gt;THREADS&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;4
&lt;span class="nv"&gt;BAD_NODE&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;server1

&lt;span class="nb"&gt;cd&lt;/span&gt; &lt;span class="nv"&gt;$SRCDIR&lt;/span&gt;

&lt;span class="c"&gt;# COPY&lt;/span&gt;
&lt;span class="c"&gt;# note the combination of -print0 and -0!&lt;/span&gt;
find &lt;span class="o"&gt;{&lt;/span&gt;a..z&lt;span class="o"&gt;}&lt;/span&gt;* &lt;span class="o"&gt;{&lt;/span&gt;A..Z&lt;span class="o"&gt;}&lt;/span&gt;* &lt;span class="o"&gt;{&lt;/span&gt;0..9&lt;span class="o"&gt;}&lt;/span&gt;* -mindepth &lt;span class="m"&gt;1&lt;/span&gt; -maxdepth &lt;span class="m"&gt;1&lt;/span&gt; -print0 &lt;span class="p"&gt;|&lt;/span&gt; &lt;span class="se"&gt;\&lt;/span&gt;
    xargs -0 -n1 -P&lt;span class="nv"&gt;$THREADS&lt;/span&gt; -I% &lt;span class="se"&gt;\&lt;/span&gt;
        &lt;span class="nv"&gt;$RSYNC_PROG&lt;/span&gt; &lt;span class="nv"&gt;$RSYNC_OPTS&lt;/span&gt; &lt;span class="s2"&gt;&amp;quot;%&amp;quot;&lt;/span&gt; &lt;span class="nv"&gt;$BAD_NODE&lt;/span&gt;:&lt;span class="nv"&gt;$DESTDIR&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Pay attention to the source/destination paths, the number of &lt;code&gt;THREADS&lt;/code&gt;, and the &lt;code&gt;BAD_NODE&lt;/code&gt; name, then you should be ready to roll.&lt;/p&gt;
&lt;h3&gt;The magic, explained&lt;/h3&gt;
&lt;p&gt;It's a bit of magic, but here are the important parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;The &lt;code&gt;-aAXv&lt;/code&gt; options to &lt;code&gt;rsync&lt;/code&gt; tell it to &lt;strong&gt;archive&lt;/strong&gt;, preserve &lt;strong&gt;ACLs&lt;/strong&gt;, and preserve &lt;strong&gt;eXtended&lt;/strong&gt; attributes.  Extended attributes are &lt;a href="http://joejulian.name/blog/what-is-this-new-glusterfs-directory-in-33"&gt;critically important in GlusterFS &amp;gt;= 3.3&lt;/a&gt;, and also if you're using SELinux.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;--exclude=.glusterfs&lt;/code&gt; option to &lt;code&gt;rsync&lt;/code&gt; tells it to ignore this directory at the root of the directory, as the self-heal daemon — &lt;code&gt;glustershd&lt;/code&gt; — will rebuild it based on the files' extended attributes once we restart the &lt;code&gt;glusterd&lt;/code&gt; service.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;--relative&lt;/code&gt; option to &lt;code&gt;rsync&lt;/code&gt; is so we don't have to bother constructing the destination path, as &lt;code&gt;rsync&lt;/code&gt; will imply the path is relative to our destination's top.&lt;/li&gt;
&lt;li&gt;The &lt;code&gt;RSYNC_RSH&lt;/code&gt; options influence &lt;code&gt;rsync&lt;/code&gt;'s use of SSH, basically telling it to use very weak encryption and disable any unnecessary features for non-interactive sessions (tty, X11, etc).&lt;/li&gt;
&lt;li&gt;Using &lt;code&gt;find&lt;/code&gt; with &lt;code&gt;-mindepth 1&lt;/code&gt; and &lt;code&gt;-maxdepth 1&lt;/code&gt; just means we concentrate on files/directories 1 level below each directory in our immediate hierarchy.
-Using &lt;code&gt;xargs&lt;/code&gt; with &lt;code&gt;-n1&lt;/code&gt; and &lt;code&gt;-P&lt;/code&gt; tells it to use 1 argument per command line, and to launch &lt;code&gt;$THREADS&lt;/code&gt; number of processes at a time.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Hope this helps!&lt;/p&gt;
&lt;p&gt;This was &lt;a href="https://mjanja.ch/2014/07/parallelizing-rsync/"&gt;originally posted&lt;/a&gt; on my personal blog; re-posted here for posterity.&lt;/p&gt;</summary><category term="linux"></category><category term="rsync"></category></entry><entry><title>Hacking on the Eudyptula Challenge</title><link href="https://nairobilug.or.ke/2014/05/hacking-on-eudyptula.html" rel="alternate"></link><updated>2014-05-26T23:00:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2014-05-26:2014/05/hacking-on-eudyptula.html</id><summary type="html">&lt;p&gt;Last weekend a few of us met up at a coffee shop in Nairobi to hack on the &lt;a href="http://eudyptula-challenge.org/"&gt;Eudyptula Challenge&lt;/a&gt;. From their website, the Eudyptula Challenge is:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;... a series of programming exercises for the Linux kernel, that start from a very basic “Hello world” kernel module, moving on up in complexity to getting patches accepted into the main Linux kernel source tree.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;With coffee, anything is possible!&lt;/h2&gt;
&lt;p&gt;Kaldis Coffee House in downtown Nairobi has free Wi-Fi, coffee, decent food, and it’s not too busy on Saturday mornings, so we got a nice table in the corner and dove in.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Hacking on Eudyptula at Kaldis" src="/images/eudyptula-may-2014.jpg" title="Hacking on Eudyptula at Kaldis" /&gt;&lt;/p&gt;
&lt;p&gt;While none of us are new to GNU/Linux or development, it still took us several hours to set up our build environments, text editors, email clients, and to read up on the Linux kernel’s build system and programming conventions. We learned a lot, and had a good time doing it!&lt;/p&gt;
&lt;h2&gt;Little penguins...&lt;/h2&gt;
&lt;p&gt;BTW, &lt;em&gt;&lt;a href="https://en.wikipedia.org/wiki/Eudyptula"&gt;Eudyptula&lt;/a&gt;&lt;/em&gt; is the scientific classification for a genus of penguins containing two species; the little blue penguin and the white-flippered penguin. The more you know.™ ;)&lt;/p&gt;
&lt;p&gt;This was originally &lt;a href="https://mjanja.ch/2014/05/hacking-on-the-eudyptula-challenge/"&gt;posted on&lt;/a&gt; on my personal blog; re-posted here for posterity.&lt;/p&gt;</summary><category term="linux"></category><category term="programming"></category></entry><entry><title>Installing Debian Jessie on the Acer C710-2833 Chromebook</title><link href="https://nairobilug.or.ke/2014/03/installing-debian-jessie-on-the-acer-c710-2833-chromebook.html" rel="alternate"></link><updated>2014-03-19T19:15:00+03:00</updated><author><name>Muriithi Frederick Muriuki</name></author><id>tag:nairobilug.or.ke,2014-03-19:2014/03/installing-debian-jessie-on-the-acer-c710-2833-chromebook.html</id><summary type="html">&lt;h2&gt;Introduction&lt;/h2&gt;
&lt;p&gt;Hey there.&lt;/p&gt;
&lt;p&gt;I have recently had need to get a machine for work that is easy to lug around, affordable and has a decent battery life. While I already have a laptop (Presario CQ62), it has grown old and its battery life is in the shitter.&lt;/p&gt;
&lt;p&gt;After shopping around, I settled for the Acer C710-2833 Chromebook (I would have picked a newer model, but there is not one in our market yet, and importing one would have made it quickly unaffordable - thank the new government).&lt;/p&gt;
&lt;p&gt;Now, while Chrome OS - the operating system that comes with the machines - is a nice (great?) operating system, for a freelance developer like me, it renders the machine useless for much of my day to day work. I found the need therefore to make it useful for me.&lt;/p&gt;
&lt;h2&gt;Preparation&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;DISCLAIMER&lt;/strong&gt;: FROM THIS POINT FORWARD, ANYTHING YOU DO WITH YOUR MACHINE IS YOUR FAULT. IF IT BREAKS, OR YOU BRICK IT, OR CAUSE A NUCLEAR HOLOCAUST, OR ANYTHING ELSE FOR THAT MATTER, YOU CAN ONLY BLAME YOURSELF.&lt;/p&gt;
&lt;p&gt;Now that that is out of the way, shall we proceed.&lt;/p&gt;
&lt;p&gt;First off, let us start with where you can acquire the machine in Kenya. I got my machine at Ebrahim Electronics Limited along Kimathi Street. The machine costs a whooping Kshs 19,000. Also, do not forget to carry the manuals with you like I did.&lt;/p&gt;
&lt;p&gt;I would recommend you also get yourself a flash-disk at this point.&lt;/p&gt;
&lt;p&gt;So now you have your spanking new machine. Make sure to claim your free 100GB storage on google drive before you proceed. Also, BACKUP any user data you might have put on the machine&lt;/p&gt;
&lt;h2&gt;Reading Material&lt;/h2&gt;
&lt;p&gt;The process that is involved is tricky, and while I try to give a roadmap, I will not give the instructions, rather, I will point to the various resources I found useful&lt;/p&gt;
&lt;p&gt;SERIOUSLY, DO NOT JUST JUMP IN AND START COPYING AND PASTING COMMANDS! YOU WILL BRICK YOUR MACHINE. YOU HAVE BEEN WARNED.&lt;/p&gt;
&lt;h3&gt;Getting to Developer Mode&lt;/h3&gt;
&lt;p&gt;The chromebooks have two modes:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Normal user mode&lt;/li&gt;
&lt;li&gt;Developer mode&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Read &lt;a href="http://www.chromium.org/chromium-os/chromiumos-design-docs/developer-mode"&gt;this&lt;/a&gt;, and &lt;a href="http://www.chromium.org/chromium-os/developer-information-for-chrome-os-devices/acer-c7-chromebook"&gt;this&lt;/a&gt; for more information on developer mode&lt;/p&gt;
&lt;h3&gt;CoreBoot&lt;/h3&gt;
&lt;p&gt;These links are about coreboot. PLEASE READ THROUGH THEM A COUPLE OF TIMES before attempting anything
For an introduction to coreboot see &lt;a href="https://johnlewis.ie/mediawiki/index.php?title=Coreboot_on_Chromebooks"&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;a href="http://johnlewis.ie/coreboot-on-chromebooks/pre-built-firmware/"&gt;Here&lt;/a&gt; you can find a list of the existing coreboot firmware. DO NOT RUSH JUST YET. Read on.&lt;/p&gt;
&lt;h2&gt;Installing&lt;/h2&gt;
&lt;h3&gt;Getting the ISO&lt;/h3&gt;
&lt;p&gt;We now need to download an iso image to use as the installation source. It is important that you research and figure out what processor your machine uses. For the C710-2833, it uses the &lt;a href="http://ark.intel.com/products/56056/Intel-Celeron-Processor-847-2M-Cache-1_10-GHz"&gt;Intel Celeron 847&lt;/a&gt;. This is an x86_64 architecture, otherwise known as amd64.&lt;/p&gt;
&lt;p&gt;Armed with that knowledge, get to &lt;a href="http://www.debian.org/"&gt;http://www.debian.org&lt;/a&gt; and get the relevant image.&lt;/p&gt;
&lt;p&gt;At this time, it is recommended that you get Debian Jessie &lt;a href="http://www.debian.org/devel/debian-installer/"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;h3&gt;Ready To Go&lt;/h3&gt;
&lt;p&gt;Now, you have read up on coreboot, you have the image all that remains is the process.&lt;/p&gt;
&lt;p&gt;Start off &lt;a href="https://wiki.debian.org/InstallingDebianOn/Acer/C710-2615-Chromebook"&gt;here&lt;/a&gt; - you will get some information on the current status of your machine. It is also where you will finish your journey.&lt;/p&gt;
&lt;p&gt;Once you have read through that at least twice, now start the actual installation. The process to follow is &lt;a href="https://johnlewis.ie/mediawiki/index.php?title=Flashing_stock_firmware_to_a_coreboot_build_on_Acer_C7_%28C710%29"&gt;here&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;For the core boot, I used the 'Grub2 for Intel Celeron 847' with an md5 sum of &lt;code&gt;9c5993518ddf97ab4c4cf7e0a2f84570&lt;/code&gt;. I picked it because I have used grub2 before and felt comfortable starting off in a farmiliar place. You are welcome to try a different one if you know what you are doing.&lt;/p&gt;
&lt;p&gt;If you follow the instructions carefully, you should get through without problems.&lt;/p&gt;
&lt;h3&gt;Finally&lt;/h3&gt;
&lt;p&gt;Now you have Debian on your system, it is time to do the post-installation steps. As I told you, those are found on the page you &lt;a href="https://wiki.debian.org/InstallingDebianOn/Acer/C710-2615-Chromebook"&gt;started off with&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Great! Now go ye and be productive!&lt;/p&gt;
&lt;hr /&gt;
&lt;h2&gt;EDITS&lt;/h2&gt;
&lt;p&gt;April 21, 2014: Sometimes the trackpad does not work - to correct that, you could do the following (from &lt;a href="http://marstella.net/?p=278"&gt;marstella.net&lt;/a&gt; also, thanks to eebrah)&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;
&lt;p&gt;Edit &lt;code&gt;/etc/modprobe.d/blacklist.conf&lt;/code&gt; and include the following line&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;blacklist chromeos_laptop
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Edit &lt;code&gt;/etc/modules&lt;/code&gt; and include the following lines:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;i2c-i801
i2c-dev
chromeos_laptop
cyapa
&lt;/pre&gt;&lt;/div&gt;


&lt;/li&gt;
&lt;/ol&gt;</summary><category term="hardware"></category><category term="Chromebook"></category><category term="Debian"></category></entry><entry><title>Meetup Summary (March, 2014)</title><link href="https://nairobilug.or.ke/2014/03/meetup-march-2014.html" rel="alternate"></link><updated>2014-03-02T21:01:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2014-03-02:2014/03/meetup-march-2014.html</id><summary type="html">&lt;p&gt;11 or 12 people showed up, including two first-time members (hi, Ken and friend!).  Off the top of my head, the topics discussed included:&lt;/p&gt;
&lt;h3&gt;Serious stuff&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Using GPG Public Keys for signing and encrypting emails (standards, terminology, motivation, etc)&lt;ul&gt;
&lt;li&gt;Several members have, in the last weeks, set up and exchanged keys&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scheduling a key-signing party where attendees bring their photo IDs and GPG public key IDs so people can verify that their real identity matches their GPG identity on the GPG Public Key Infrastructure and then "sign" eachother's keys&lt;ul&gt;
&lt;li&gt;Could be Saturday, March 8th?&lt;/li&gt;
&lt;li&gt;Need to make a push to educate people (via blog post?) so they are prepared for the party (don't come with laptops or expecting to create/publish keys!)&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;Scheduling a second, more formal LUG meetup every month; perhaps seminars or "lightning" talks&lt;ul&gt;
&lt;li&gt;The idea would be to give people a forum to share technical things they're doing, and let people practice public speaking skills etc&lt;/li&gt;
&lt;li&gt;Venue should be somewhere in tao to make it easy for people to be on time, possibly University of Nairobi library (with KENET connections?)&lt;/li&gt;
&lt;li&gt;Perhaps could be the 3rd Saturday of the month&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Not-so-serious stuff&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Progress of the current Nairobi GNU/Linux Users Group book club book, Stephen King's &lt;em&gt;The Stand&lt;/em&gt;.  sticky and sentinelprime are ~50% through, but emk and raywan haven't started&lt;/li&gt;
&lt;li&gt;emk's gangsta beard will rival that of Rick Ross soon&lt;/li&gt;
&lt;li&gt;Proper pronunciation of "Linux" (&lt;a href="http://safalra.com/science/linguistics/linux-pronunciation/"&gt;Linus says "Lih-nux"&lt;/a&gt;)&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Wat?&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Proper pronunciation of "doge"&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Proof that it happened:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Group shot" src="/images/meetup-march-2014.jpg" title="Nairobi GNU/Linux Users Group members" /&gt;&lt;/p&gt;
&lt;p&gt;See you for the next meeting (April 5th, 2014!)&lt;/p&gt;</summary><category term="KFC"></category><category term="meetup"></category></entry><entry><title>Scars in Web App Trenches</title><link href="https://nairobilug.or.ke/2014/02/scars-in-web-app-trenches.html" rel="alternate"></link><updated>2014-02-17T13:00:00+03:00</updated><author><name>Muriithi Frederick Muriuki</name></author><id>tag:nairobilug.or.ke,2014-02-17:2014/02/scars-in-web-app-trenches.html</id><summary type="html">&lt;p&gt;Hey there.&lt;/p&gt;
&lt;p&gt;I have been developing web applications for a while now, working freelance on oDesk, and from my work, I can state I do have some experience in doing this. Now, I will not claim to be a web-app ninja, but I will try to state my case as objectively as I can, but you decide how much salt you'll take it with. Deal?&lt;/p&gt;
&lt;h2&gt;HTML - The M is for Markup&lt;/h2&gt;
&lt;p&gt;From what I have come to understand from the gurus and ninjas in this field, HTML was built as a markup language. It was meant to give meaning to the content of the page, e.g.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&amp;lt; h1 &amp;gt; is greater than &amp;lt; h2 &amp;gt;, which in turn is greater than &amp;lt; h3 &amp;gt; etc&lt;/li&gt;
&lt;li&gt;&amp;lt; form &amp;gt; represents an electronic form where you can fill in and submit data&lt;/li&gt;
&lt;li&gt;&amp;lt; button &amp;gt; and &amp;lt; input type='button' ... &amp;gt; represent input elements that can be used to activate certain actions like submit forms, etc&lt;/li&gt;
&lt;li&gt;&amp;lt; a &amp;gt; - the anchor tag, is meant to represent links to a different part of the page, other pages, or another site&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and many others. . . (For awesome HTML, CSS and Javascript tutorials, click &lt;a href="http://htmldog.com/"&gt;here&lt;/a&gt;)&lt;/p&gt;
&lt;p&gt;Now, if there is one thing that I have found painful in my work, it is when people make use on the anchor tag to submit forms.&lt;/p&gt;
&lt;p&gt;Why?&lt;/p&gt;
&lt;p&gt;I am one of those people still living in a third world country (and if things keep going the way they are, we just might have to come up with a whole new class beneath that for the country), and as such, bandwidth is expensive (I dare say, artificially so).&lt;/p&gt;
&lt;p&gt;Now, we all know that the tag &amp;lt; input type='submit' ... &amp;gt; will submit any form it is in, no questions asked, but 'NOOOOOOOOO!', we have to bloat that up by getting rid of it, replacing it with a link, and then using the jQuery library to submit the form. A form submission, I tell you!&lt;/p&gt;
&lt;h3&gt;But The Web is Javascript!&lt;/h3&gt;
&lt;p&gt;For all that have this argument, I refer you &lt;a href="http://motherfuckingwebsite.com/"&gt;here&lt;/a&gt;. Now, tell me you cannot see the content in that site. Then, riddle me this, before Javascript, jQuery, and others came along, pray tell, how were people submitting their html forms?&lt;/p&gt;
&lt;p&gt;Now understand this &lt;strong&gt;I love Javascript&lt;/strong&gt; and though I am not a jQuery ninja, I cannot argue against it's merits, but if we are going to use javascript everywhere, we might as well start killing mosquitoes with handguns, or slings, or catapults (take your pick).&lt;/p&gt;
&lt;h2&gt;Back to the Basics&lt;/h2&gt;
&lt;p&gt;Hear me out, before you fetch the noose. I am making a simple suggestion here, based on the experience I have had with web applications, and even some plain websites.&lt;/p&gt;
&lt;p&gt;When I land on your site, almost always, I am searching for information about your company, skill, etc. You, on the other hand, decide to make me have to struggle further to find the friggin content by putting those silly pictures, animations and shiznit in my path. Then, to insult me further, you make it so that, if I turn javascript off (It's off by default on my browser), I cannot see your content.
As if you have not hurt me enough, you make all your forms submit only via javascript/jQuery.&lt;/p&gt;
&lt;p&gt;DEAR &lt;deity&gt;! I cannot count the number of times I have left websites and gone looking for other options due to this.&lt;/p&gt;
&lt;p&gt;First, you eat away my bandwidth with silly content, then you force me to use even more of my bandwidth, just to get functionality that is already built into html.&lt;/p&gt;
&lt;h2&gt;Collaboration&lt;/h2&gt;
&lt;p&gt;Let us view another scenario. You have to collaborate with a person in a different timezone building a web application. Now, you are a javascript, jQuery, etc ninja, and you can build anything in it. Her/him, not so much, but they are good at their PHP, Ruby, Python, C or whatever language they use on the backend.&lt;/p&gt;
&lt;p&gt;Now, I do not know what you think, but I dare say, it is easier to pass to each other data, than force the backend to rely on the design of the frontend. Think also, of when you decide you want to change the look and feel of the website, then you have to make changes to both the front and backends, introducing new bugs, and possibly throwing away months of work debugging the data communication etc.&lt;/p&gt;
&lt;p&gt;Now, if you had simply passed data between the frontend and backend, say using &lt;strong&gt;json, xml, plain text, plain html&lt;/strong&gt; and others, then you can change the frontend any time without worrying about the backend, since the data interchange format is standardised, agreed upon, and &lt;strong&gt;DE&lt;/strong&gt;fucking&lt;strong&gt;BUGGED!&lt;/strong&gt;.&lt;/p&gt;
&lt;p&gt;The backend guy/gal, can now concentrate on building and testing the backend, even with plain, unstyled, ugly, but functional html, and you can concentrate on styling (CSS) and behaviour (Javascript), without breaking the backend every time you make a tiny little change to the front end.&lt;/p&gt;
&lt;p&gt;Now, think of your client, and how happy they are, every time they contact you to change the look and feel of the website, and you do that in a few weeks without breaking the backend, and they think you are a god!
Yeah, keep doing the shit you're doing, and that will never happen.&lt;/p&gt;
&lt;p&gt;I'm angry, and so are you. Let me know what you think in the comments. Try to be civil, though I probably haven't.&lt;/p&gt;</summary><category term="web applications"></category><category term="web development"></category></entry><entry><title>Meetup Summary (February, 2014)</title><link href="https://nairobilug.or.ke/2014/02/meetup-february-2014.html" rel="alternate"></link><updated>2014-02-06T16:00:00+03:00</updated><author><name>Njagi Mwaniki</name></author><id>tag:nairobilug.or.ke,2014-02-06:2014/02/meetup-february-2014.html</id><summary type="html">&lt;p&gt;16 guys showed up (staggered).
I had a friend attend for the first time and he liked it.&lt;/p&gt;
&lt;h3&gt;3D printer&lt;/h3&gt;
&lt;p&gt;Well great news guys have decided to build a 3D printer. Updates on that will be blogged about sooner than later I hope. I for one are very excited that we're doing such.&lt;/p&gt;
&lt;h3&gt;emk breaks opSec&lt;/h3&gt;
&lt;p&gt;So he decided to show up after hiding for a very very long while. He wanted it noted that he refrained from kicking zipper's teeth in. &lt;/p&gt;
&lt;p&gt;He has a gangsta beard which was totally unexpected.&lt;/p&gt;
&lt;h3&gt;Stuff&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;There was talk of getting devices into the country as a group with eebrah fascilitating that. This was very exciting since it would bring prices down for most things.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;r0ckwilda{-_-} shared some interesting things he is doing with blender. I can't wait to see how that goes.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Sadly this time I didn't get a chance to hear Karibe talk about Physics and electronics. I always look forward to those that's for sure. You can't beat having a physicist around.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Oh plus everyone is talking about a book called the stand. It's really big and that just makes everyone love it haha I kid.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;The absence of theBOFH was noted with great concern.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;I noted that there wasn't much talk/argument on distros. I always like those.&lt;/p&gt;
&lt;p&gt;Here are some cool pics from the event that was.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Group shot0" src="/images/meetup-february-2014-0.jpg" title="Nairobi GNU/Linux Users Group members" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;img alt="Group shot1" src="/images/meetup-february-2014-1.jpg" title="Nairobi GNU/Linux Users Group members" /&gt;&lt;/p&gt;
&lt;p&gt;Guys had a great time. See you at KFC Kimathi Street on March 1st, 2014.
Happy hacking!!&lt;/p&gt;</summary><category term="KFC"></category><category term="meetup"></category></entry><entry><title>Meetup Summary (January, 2014)</title><link href="https://nairobilug.or.ke/2014/01/meetup-january-2014.html" rel="alternate"></link><updated>2014-01-11T16:00:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2014-01-11:2014/01/meetup-january-2014.html</id><summary type="html">&lt;p&gt;A major highlight of the January, 2014 meetup was having sixteen people show up (a new record!).  Other than that, there were lots of lively discussions of technology goings ons, releases, politics etc.&lt;/p&gt;
&lt;h3&gt;Some topic highlights (from memory):&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;The debate over Debian voting to replace SysV Init with either &lt;a href="http://slashdot.org/story/13/10/28/1621219/debian-to-replace-sysvinit-switch-to-systemd-or-upstart"&gt;Upstart or systemd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;Using GPG for both signatures and encryption of email, and how to manage keychains on multiple computers&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If I missed anything, leave it in the comments (or send a pull request ;).&lt;/p&gt;
&lt;h3&gt;Proof we were there&lt;/h3&gt;
&lt;p&gt;Discussing all teh things...&lt;/p&gt;
&lt;p&gt;&lt;img alt="Group shot" src="/images/meetup-january-2014.jpg" title="Nairobi GNU/Linux Users Group members" /&gt;&lt;/p&gt;
&lt;h3&gt;February meetup&lt;/h3&gt;
&lt;p&gt;Remember, we meet the first Saturday of the month, meaning February's meetup should be February 7th.  See you there!&lt;/p&gt;</summary><category term="KFC"></category><category term="meetup"></category></entry><entry><title>Experimenting with AES-NI</title><link href="https://nairobilug.or.ke/2013/11/experimenting-with-aesni.html" rel="alternate"></link><updated>2013-11-10T13:00:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2013-11-10:2013/11/experimenting-with-aesni.html</id><summary type="html">&lt;p&gt;Ever since the &lt;a href="https://en.wikipedia.org/wiki/Sandy_Bridge"&gt;Sandy Bridge microarchitecture&lt;/a&gt;, Intel CPUs have been coming with hardware-accelerated &lt;abbr title="Advanced Encryption Standard"&gt;AES&lt;/abbr&gt; support (aka "AES-NI", &lt;em&gt;new instructions&lt;/em&gt;).  I figured it would be interesting see a comparison between AES with and without the hardware acceleration on my &lt;a href="http://ark.intel.com/products/65707"&gt;Intel Core i5-3317U CPU&lt;/a&gt; (Ivy Bridge) on Arch Linux.&lt;/p&gt;
&lt;p&gt;According to &lt;a href="http://openssl.6102.n7.nabble.com/having-a-lot-of-troubles-trying-to-get-AES-NI-working-td44285.html"&gt;a post&lt;/a&gt; on the OpenSSL Users mailing list, you can force &lt;code&gt;openssl&lt;/code&gt; to avoid hardware AES instructions using the &lt;code&gt;OPENSSL_ia32cap&lt;/code&gt; environment variable.&lt;/p&gt;
&lt;h2&gt;Benchmarks&lt;/h2&gt;
&lt;p&gt;First, with AES-NI enabled (the default, on hardware that supports it):&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; openssl speed -elapsed -evp aes-128-cbc
&lt;span class="go"&gt;You have chosen to measure elapsed time instead of user CPU time.&lt;/span&gt;
&lt;span class="go"&gt;Doing aes-128-cbc for 3s on 16 size blocks: 57196857 aes-128-cbc&amp;#39;s in 3.00s&lt;/span&gt;
&lt;span class="go"&gt;Doing aes-128-cbc for 3s on 64 size blocks: 15343650 aes-128-cbc&amp;#39;s in 3.00s&lt;/span&gt;
&lt;span class="go"&gt;Doing aes-128-cbc for 3s on 256 size blocks: 3897351 aes-128-cbc&amp;#39;s in 3.00s&lt;/span&gt;
&lt;span class="go"&gt;Doing aes-128-cbc for 3s on 1024 size blocks: 978726 aes-128-cbc&amp;#39;s in 3.00s&lt;/span&gt;
&lt;span class="go"&gt;Doing aes-128-cbc for 3s on 8192 size blocks: 122310 aes-128-cbc&amp;#39;s in 3.00s&lt;/span&gt;
&lt;span class="go"&gt;OpenSSL 1.0.1e 11 Feb 2013&lt;/span&gt;
&lt;span class="go"&gt;built on: Sun Oct 20 14:49:13 CEST 2013&lt;/span&gt;
&lt;span class="go"&gt;options:bn(64,64) rc4(16x,int) des(idx,cisc,16,int) aes(partial) idea(int) blowfish(idx) &lt;/span&gt;
&lt;span class="go"&gt;compiler: gcc -fPIC -DOPENSSL_PIC -DZLIB -DOPENSSL_THREADS -D_REENTRANT -DDSO_DLFCN -DHAVE_DLFCN_H -Wa,--noexecstack -march=x86-64 -mtune=generic -O2 -pipe -fstack-protector --param=ssp-buffer-size=4 -m64 -DL_ENDIAN -DTERMIO -O3 -Wall -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DMD5_ASM -DAES_ASM -DVPAES_ASM -DBSAES_ASM -DWHIRLPOOL_ASM -DGHASH_ASM&lt;/span&gt;
&lt;span class="go"&gt;The &amp;#39;numbers&amp;#39; are in 1000s of bytes per second processed.&lt;/span&gt;
&lt;span class="go"&gt;type             16 bytes     64 bytes    256 bytes   1024 bytes   8192 bytes&lt;/span&gt;
&lt;span class="go"&gt;aes-128-cbc     305049.90k   327331.20k   332573.95k   334071.81k   333987.84k&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;Then, setting the capability mask to turn off the hardware AES features:&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="gp"&gt;$&lt;/span&gt; &lt;span class="nv"&gt;OPENSSL_ia32cap&lt;/span&gt;&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s2"&gt;&amp;quot;~0x200000200000000&amp;quot;&lt;/span&gt; openssl speed -elapsed -evp aes-128-cbc
&lt;span class="go"&gt;You have chosen to measure elapsed time instead of user CPU time.&lt;/span&gt;
&lt;span class="go"&gt;Doing aes-128-cbc for 3s on 16 size blocks: 27883366 aes-128-cbc&amp;#39;s in 3.00s&lt;/span&gt;
&lt;span class="go"&gt;Doing aes-128-cbc for 3s on 64 size blocks: 7736907 aes-128-cbc&amp;#39;s in 3.00s&lt;/span&gt;
&lt;span class="go"&gt;Doing aes-128-cbc for 3s on 256 size blocks: 1949328 aes-128-cbc&amp;#39;s in 3.00s&lt;/span&gt;
&lt;span class="go"&gt;Doing aes-128-cbc for 3s on 1024 size blocks: 498847 aes-128-cbc&amp;#39;s in 3.00s&lt;/span&gt;
&lt;span class="go"&gt;Doing aes-128-cbc for 3s on 8192 size blocks: 62446 aes-128-cbc&amp;#39;s in 3.00s&lt;/span&gt;
&lt;span class="go"&gt;OpenSSL 1.0.1e 11 Feb 2013&lt;/span&gt;
&lt;span class="go"&gt;built on: Sun Oct 20 14:49:13 CEST 2013&lt;/span&gt;
&lt;span class="go"&gt;options:bn(64,64) rc4(16x,int) des(idx,cisc,16,int) aes(partial) idea(int) blowfish(idx) &lt;/span&gt;
&lt;span class="go"&gt;compiler: gcc -fPIC -DOPENSSL_PIC -DZLIB -DOPENSSL_THREADS -D_REENTRANT -DDSO_DLFCN -DHAVE_DLFCN_H -Wa,--noexecstack -march=x86-64 -mtune=generic -O2 -pipe -fstack-protector --param=ssp-buffer-size=4 -m64 -DL_ENDIAN -DTERMIO -O3 -Wall -DOPENSSL_IA32_SSE2 -DOPENSSL_BN_ASM_MONT -DOPENSSL_BN_ASM_MONT5 -DOPENSSL_BN_ASM_GF2m -DSHA1_ASM -DSHA256_ASM -DSHA512_ASM -DMD5_ASM -DAES_ASM -DVPAES_ASM -DBSAES_ASM -DWHIRLPOOL_ASM -DGHASH_ASM&lt;/span&gt;
&lt;span class="go"&gt;The &amp;#39;numbers&amp;#39; are in 1000s of bytes per second processed.&lt;/span&gt;
&lt;span class="go"&gt;type             16 bytes     64 bytes    256 bytes   1024 bytes   8192 bytes&lt;/span&gt;
&lt;span class="go"&gt;aes-128-cbc     148711.29k   165054.02k   166342.66k   170273.11k   170519.21k&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;You can see that hardware-accelerated AES is pretty consistently &lt;strong&gt;twice&lt;/strong&gt; as fast as the implementation without &lt;em&gt;aesni&lt;/em&gt;.  So it's not an exponential win, but getting &lt;strong&gt;twice&lt;/strong&gt; the performance is certainly very serious!  This is great for not only for servers using AES encryption (SSL/TLS, hello!), but also for consumers wanting to connect to said servers as well as things like full-disk encryption.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; It seems Arch Linux's OpenSSL is built with AES-NI support but not as an &lt;em&gt;engine&lt;/em&gt;, so &lt;code&gt;openssl speed&lt;/code&gt; could be misleading (ie, you'd see no difference with or without the capabilities masked).  To get the AES-NI support you need to use &lt;code&gt;-evp&lt;/code&gt; ("envelope") mode, which is some sort of &lt;a href="http://wiki.openssl.org/index.php/EVP"&gt;high-level interface&lt;/a&gt; for crypto functions in OpenSSL.&lt;/p&gt;
&lt;p&gt;This was originally &lt;a href="https://mjanja.ch/2013/11/disabling-aes-ni-on-linux-openssl/"&gt;posted on&lt;/a&gt; on my personal blog; re-posted here for posterity.&lt;/p&gt;</summary><category term="linux"></category><category term="crypto"></category></entry><entry><title>Meetup Summary (November, 2013)</title><link href="https://nairobilug.or.ke/2013/11/meetup-november-2013.html" rel="alternate"></link><updated>2013-11-02T22:33:00+03:00</updated><author><name>Alan Orth</name></author><id>tag:nairobilug.or.ke,2013-11-02:2013/11/meetup-november-2013.html</id><summary type="html">&lt;p&gt;A major highlight of the November, 2013 meetup was having fourteen people show up; this was perhaps the most successful meetup since we began in 2012... Other than that, there were lots of lively discussions of technology goings ons, releases, politics etc.&lt;/p&gt;
&lt;h3&gt;Some topic highlights (from memory):&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;Fedora 20 beta (and therefore final) &lt;a href="https://lists.fedoraproject.org/pipermail/devel/2013-October/190689.html"&gt;being delayed by one week&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://blogs.cisco.com/collaboration/open-source-h-264-removes-barriers-webrtc"&gt;Cisco releasing a BSD-licensed H.264 implementation&lt;/a&gt; (as well as binaries) and footing the licensing bill for users of the binary (ie, Mozilla Firefox, who &lt;a href="https://blog.mozilla.org/blog/2013/10/30/video-interoperability-on-the-web-gets-a-boost-from-ciscos-h-264-codec/"&gt;has said&lt;/a&gt; they will integrate this)&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.openbsd.org/54.html"&gt;OpenBSD 5.4 release&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;The debate over Debian voting to replace SysV Init with either &lt;a href="http://slashdot.org/story/13/10/28/1621219/debian-to-replace-sysvinit-switch-to-systemd-or-upstart"&gt;Upstart or systemd&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;How to best use the recently-registered &lt;a href="https://twitter.com/nairobilug"&gt;@nairobilug&lt;/a&gt; twitter account&lt;/li&gt;
&lt;li&gt;How POSIX is limiting innovation (and the creep of "Linux-isms" into POSIX)&lt;/li&gt;
&lt;li&gt;RAID vs JBOD&lt;/li&gt;
&lt;li&gt;&lt;code&gt;telnet&lt;/code&gt; as a TCP/IP swiss army knife&lt;/li&gt;
&lt;li&gt;Processes vs threads&lt;/li&gt;
&lt;li&gt;The epic ending of last month's Nairobi GNU/Linux Users Group book club book, &lt;em&gt;The Picture of Dorian Gray&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;The possibility of going whitewater rafting in Uganda in December (as the Nairobi GNU/Linux Users Group "Outdoor Explorers", a related, but unofficial affiliate of the LUG)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If I missed anything, leave it in the comments (or send a pull request ;).&lt;/p&gt;
&lt;h3&gt;Proof we were there&lt;/h3&gt;
&lt;p&gt;Discussing all teh things...&lt;/p&gt;
&lt;p&gt;&lt;img alt="Group shot" src="/images/meetup-november-2013.jpg" title="Nairobi GNU/Linux Users Group members" /&gt;&lt;/p&gt;
&lt;h3&gt;December meetup&lt;/h3&gt;
&lt;p&gt;Remember, we meet the first Saturday of the month, meaning December's meetup should be December 7th.  See you there!&lt;/p&gt;</summary><category term="KFC"></category><category term="meetup"></category></entry><entry><title>October NairobiLUG Meetup</title><link href="https://nairobilug.or.ke/2013/10/october-nairobilug-meetup.html" rel="alternate"></link><updated>2013-10-02T12:00:00+03:00</updated><author><name>Mwaoshe Njemah</name></author><id>tag:nairobilug.or.ke,2013-10-02:2013/10/october-nairobilug-meetup.html</id><summary type="html">&lt;p&gt;We will be holding our October GNU/Linux User Group Meetup on 5th October between 04.00 – 06.00 pm EAT (GMT +3) at KFC Kimathi Street. We traditionally meet the first Saturday of every month.&lt;/p&gt;
&lt;h3&gt;Speakers&lt;/h3&gt;
&lt;p&gt;We have this crazy format where everyone gets to speak! We talk about what we are doing with Linux and happenings in the FOSS scene locally and beyond in the past month.&lt;/p&gt;
&lt;h3&gt;RSVP&lt;/h3&gt;
&lt;p&gt;Please RSVP for the event on Google+  and join us in person at KFC or via IRC Chat (between 04.00 – 06.00 pm EAT (GMT +3))&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Google Group and Mailing List&lt;/strong&gt; &lt;a href="https://groups.google.com/group/nairobi-gnu"&gt;groups.google.com/group/nairobi-gnu&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;IRC Channel&lt;/strong&gt; #nairobilug @ freenode&lt;/p&gt;
&lt;p&gt;For non-IRC users: &lt;a href="http://webchat.freenode.net/?channels=nairobilug"&gt;webchat.freenode.net/?channels=nairobilug&lt;/a&gt;&lt;/p&gt;</summary><category term="meetup"></category><category term="kfc"></category><category term="event"></category></entry><entry><title>Funding the Nairobi Linux User Group</title><link href="https://nairobilug.or.ke/2013/09/funding-the-nairobi-lug.html" rel="alternate"></link><updated>2013-09-28T02:15:00+03:00</updated><author><name>Mwaoshe Njemah</name></author><id>tag:nairobilug.or.ke,2013-09-28:2013/09/funding-the-nairobi-lug.html</id><summary type="html">&lt;p&gt;Yesterday I had a chat with emk on IRC concerning the organization and funding of the Nairobi LUG. He suggested that we ought to introduce some sort of monthly contribution by members.&lt;/p&gt;
&lt;p&gt;Part of the reason this came up was that our domain name, nairobilug.or.ke, expired recently and money was needed to renew it.
emk felt that it would have been easier for us to come up with the money if we had a kitty with members making monthly contributions to it. He suggested that we needed funds to spread the word and recruit members.&lt;/p&gt;
&lt;p&gt;I pointed out several issues with this proposal. Collecting money would create the need for an office of the treasurer. Who would collect and keep the money? It's just a detail, but isn't the devil always in such? There would also be need for rules and regulations governing the use of the funds. I failed to point out that we do not have a registered membership. This would make collecting regular contributions from members that much harder. I feel that imposing  membership fees and/or contributions would also have the negative effect of discouraging would be members from coming on board.  &lt;/p&gt;
&lt;p&gt;So how to finance an organisation of Linux and FOSS enthusiasts?
On Thursday I had been toying with the idea of raising money for the LUG by selling Nairobi LUG swag. We might put up a store on the website and get members to purchase printed t-shirts, printed mug, and even mouse pads. The problem with this approach is that it needs money in the first place. &lt;/p&gt;
&lt;p&gt;We could always seek out sponsors, perhaps in the form of companies or other institutions working with Linux. I would be glad to hear from any. I am not too enthusiastic about the idea of a community being bankrolled by a corporate sponsor though.&lt;/p&gt;
&lt;p&gt;I am personally comfortable with the idea of donations from members whenever the need arises, with everyone contributing whatever they can , from each according to his means so to speak. When we the registered the nairobilug.or.ke domain initially, we split the cost between all those present at the meetup where the decision to register it was made.&lt;/p&gt;
&lt;p&gt;I had a similar conversation sometime ago with Fred Muriithi a fellow Nairobi LUGer, and he seemed to share many of my views on the subject.
I asked for suggestions from fellow LUGers on IRC and I hope this will be an ongoing discussion. I would also like to hear about how other Linux User Groups fund themselves, and what they use their funds for. If you have any thoughts or ideas on the subject drop by #nairobilug on Freenode IRC and share or post to the mailing list.&lt;/p&gt;
&lt;p&gt;As things stand we do not really need money for anything, save for the KES 2,320/- for renewing our .or.ke domain once a year. In the end Alan Orth and Ibrahim Ng'eno split the cost of renewing the domain. I look forward to reimbursing them my contribution at the next LUG meetup.&lt;/p&gt;</summary><category term="nairobilug"></category><category term="funding a linux user group"></category></entry><entry><title>In The Spirit of Pelican</title><link href="https://nairobilug.or.ke/2013/07/in-the-spirit-of-pelican.html" rel="alternate"></link><updated>2013-07-14T20:22:00+03:00</updated><author><name>Muriithi Frederick Muriuki</name></author><id>tag:nairobilug.or.ke,2013-07-14:2013/07/in-the-spirit-of-pelican.html</id><summary type="html">&lt;p&gt;I have to start by commending everyone involved in the Nairobi Linux User Group (nairobilug) for their various efforts to get all of us to this point.&lt;/p&gt;
&lt;p&gt;First off, I wish to thank &lt;em&gt;Mr. Alan Orth&lt;/em&gt; for introducing us (or was it just me?) to Pelican, and providing the tutorial for getting it running. Also, for setting up the system so that we can all collaborate to add content to the site.&lt;/p&gt;
&lt;p&gt;I would also like to thank the visionary fellows who had the light-bulb moment to start off the &lt;em&gt;LUG&lt;/em&gt;. Here, I specifically target &lt;em&gt;nj3ma&lt;/em&gt; and &lt;em&gt;eebrah&lt;/em&gt;. You spoke of it in university, but I was too busy chasing tail and the A's :D&lt;/p&gt;
&lt;p&gt;Then there is all the rest of you people who saw fit to join the LUG and further light the fire. I am grateful to have met all of you in person. And for those of you I have yet to meet in person, I look forward to meeting you.&lt;/p&gt;
&lt;h3&gt;And Now, a code block&lt;/h3&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;[aorth@noma: ~]$ uname -sr
Linux 3.9.9-1-ARCH
&lt;/pre&gt;&lt;/div&gt;


&lt;h3&gt;And now, a list&lt;/h3&gt;
&lt;p&gt;I could not resist doing this... here is a list of the nicks on irc as I type this:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Alfontefonte&lt;/li&gt;
&lt;li&gt;highPriestLOL&lt;/li&gt;
&lt;li&gt;raywan|away&lt;/li&gt;
&lt;li&gt;@eebrah|away&lt;/li&gt;
&lt;li&gt;Dr3amc0d3r_&lt;/li&gt;
&lt;li&gt;karfes&lt;/li&gt;
&lt;li&gt;varud&lt;/li&gt;
&lt;li&gt;@stickyboy&lt;/li&gt;
&lt;li&gt;fredmanglis&lt;/li&gt;
&lt;li&gt;r0ckwilda|away&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Shout out to all of you great peoples!!!&lt;/p&gt;</summary><category term="pelican"></category><category term="publishing"></category></entry></feed>